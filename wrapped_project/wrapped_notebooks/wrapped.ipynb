{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Environmental Setup</h1></strong>\n",
    "\n",
    "<strong>Install Required Packages:</strong> Install necessary packages using pip.\n",
    "\n",
    "<strong>Load Environment Variables:</strong> Load environment variables for Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r C:\\Users\\ezrag\\OneDrive\\Documents\\GitHub\\spotify-listening-data\\requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "SPOTIFY_CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "SPOTIFY_CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import queue\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from itertools import combinations \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Utility Functions and Initialization</h1></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>User Input Functions</h3>\n",
    "<strong>Get User ID:</strong> Function to get user ID from input.\n",
    "\n",
    "<strong>Get Number of Data Chunks:</strong> Function to get the number of data chunks from input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id():\n",
    "    \"\"\"\n",
    "    Prompt the user to enter their ID and return it in lowercase.\n",
    "\n",
    "    This function prompts the user to enter their ID, converts it to lowercase,\n",
    "    and returns the result.\n",
    "\n",
    "    Returns:\n",
    "    str: The user's ID in lowercase.\n",
    "    \"\"\"\n",
    "    user_id = input(\"Enter the user's ID: \").lower()\n",
    "    return user_id\n",
    "\n",
    "def get_num_chunks():\n",
    "    \"\"\"\n",
    "    Prompt the user to enter the number of data chunks.\n",
    "\n",
    "    This function prompts the user to enter the number of data chunks,\n",
    "    converts the input to an integer, and returns the result.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of data chunks entered by the user.\n",
    "    \"\"\"\n",
    "    num_chunks = int(input(\"Enter the number of chunks: \"))\n",
    "    return num_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Reading and Processing</h3>\n",
    "<strong>Read and Process Data:</strong> Function to read and process data from multiple JSON files.\n",
    "\n",
    "<strong>Export Data to CSV:</strong> Function to export processed data to a CSV file.\n",
    "\n",
    "<strong>Track Unique Songs:</strong> Function to track unique songs and update unique songs list.\n",
    "\n",
    "<strong>Safe Literal Eval:</strong> Function to safely evaluate literals from strings.\n",
    "\n",
    "<strong>Expand Artists Involved:</strong> Function to expand artists involved in each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_data(user_id, num_chunks, base_path='wrapped_files/'):\n",
    "    \"\"\"\n",
    "    Read and process data from multiple JSON files.\n",
    "\n",
    "    This function reads data from multiple JSON files specified by the user ID\n",
    "    and number of chunks, processes the data, and returns it as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (str): The user's ID.\n",
    "    num_chunks (int): The number of JSON files (chunks) to read.\n",
    "    base_path (str, optional): The base path to the directory containing the JSON files. \n",
    "                               Defaults to 'wrapped_files/'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the processed data.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If no data files were found or all files were empty.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        json_file = os.path.join(base_path, f'{user_id}_music_{i}.json')\n",
    "        \n",
    "        if not os.path.exists(json_file):\n",
    "            print(f\"File not found: {json_file}\")\n",
    "            continue\n",
    "        \n",
    "        with open(json_file, 'r', encoding='utf-8') as file:\n",
    "            data_list = json.load(file)\n",
    "            all_data.extend(data_list)\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No data files were found or all were empty.\")\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['user_id'] = user_id\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    print(f\"Data read successfully for {len(df)} records.\")\n",
    "    return df\n",
    "\n",
    "def export_to_csv(df, user_id):\n",
    "    \"\"\"\n",
    "    Export data to a CSV file.\n",
    "\n",
    "    This function exports the provided DataFrame to a CSV file named with the user's ID.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data to be exported.\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    csv_file = f'{user_id}_listening_data.csv'\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Data exported to {csv_file}\")\n",
    "\n",
    "def track_unique_songs(df, unique_songs_file):\n",
    "    \"\"\"\n",
    "    Track unique songs in the given DataFrame.\n",
    "\n",
    "    This function ensures the DataFrame includes the necessary columns,\n",
    "    drops duplicates within the current DataFrame, and combines new unique songs\n",
    "    with existing unique songs from a CSV file. The combined unique songs are then\n",
    "    saved back to the CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data to be processed.\n",
    "    unique_songs_file (str): The file path to the CSV file where unique songs are stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure DataFrame includes necessary columns\n",
    "    required_columns = ['trackName', 'artistName', 'external_urls']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    \n",
    "    # Drop duplicates within the current DataFrame\n",
    "    new_unique_songs = df[required_columns].drop_duplicates()\n",
    "    print(f\"Tracking {len(new_unique_songs)} unique songs.\")\n",
    "    \n",
    "    try:\n",
    "        # Attempt to load existing unique songs from the CSV file\n",
    "        existing_unique_songs = pd.read_csv(unique_songs_file)\n",
    "        print(f\"Loaded {len(existing_unique_songs)} existing unique songs.\")\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, start with an empty DataFrame\n",
    "        existing_unique_songs = pd.DataFrame(columns=required_columns)\n",
    "        print(\"No existing unique songs file found. Starting fresh.\")\n",
    "    \n",
    "    # Combine new and existing unique songs\n",
    "    combined_unique_songs = pd.concat([existing_unique_songs, new_unique_songs]).drop_duplicates()\n",
    "    \n",
    "    # Save the combined DataFrame to the CSV file\n",
    "    combined_unique_songs.to_csv(unique_songs_file, index=False)\n",
    "    print(f\"Updated unique songs saved to {unique_songs_file}.\")\n",
    "\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    \"\"\"\n",
    "    Safely evaluate a string containing a Python literal or container display.\n",
    "\n",
    "    This function attempts to safely evaluate a string containing a Python literal\n",
    "    or container display (e.g., list, dictionary). If the evaluation fails due to\n",
    "    a ValueError or SyntaxError, the original value is returned.\n",
    "\n",
    "    Parameters:\n",
    "    val (str): The string to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "    object: The evaluated Python object, or the original value if evaluation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "\n",
    "def expand_artists_involved(df):\n",
    "    \"\"\"\n",
    "    Expand and standardize the list of artists involved in each track.\n",
    "\n",
    "    This function processes the 'artists_involved' column to ensure it is correctly evaluated as a list,\n",
    "    adds the main artist to this list if not already present, standardizes the artist names to lowercase,\n",
    "    and preserves the original artist names.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'artists_involved' and 'artistName' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Updated DataFrame with expanded and standardized artist names.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    def safe_literal_eval(val):\n",
    "        try:\n",
    "            if isinstance(val, str):\n",
    "                return literal_eval(val)\n",
    "            return val\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    def add_main_artist(row):\n",
    "        if isinstance(row['artists_involved'], list):\n",
    "            if row['artistName'] not in row['artists_involved']:\n",
    "                row['artists_involved'].append(row['artistName'])\n",
    "        else:\n",
    "            row['artists_involved'] = [row['artistName']]\n",
    "        return row\n",
    "\n",
    "    df_copy = df_copy.apply(add_main_artist, axis=1)\n",
    "    \n",
    "    df_copy['standardized_artists'] = df_copy['artists_involved'].apply(lambda x: [artist.lower() for artist in x])\n",
    "    df_copy['standardized_artists_str'] = df_copy['standardized_artists'].apply(lambda x: ', '.join(x))  # Convert lists to strings\n",
    "    df_copy['original_artists'] = df_copy['artists_involved']  # Preserve original names\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "\n",
    "def check_album_art_exists(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Check if the album art for a given artist exists in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check for album art. Defaults to 'albums'.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if album art exists, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = f\"{folder}/{artist_name}.jpg\"\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def fetch_album_art(artist_name, token, folder='albums'):\n",
    "    \"\"\"\n",
    "    Fetch album art for a given artist from Spotify API and save it to the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    token (str): Spotify API access token.\n",
    "    folder (str): The folder to save the album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    search_url = f'https://api.spotify.com/v1/search?q={artist_name}&type=artist&limit=1'\n",
    "    headers = {'Authorization': f'Bearer {token}'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['artists']['items']:\n",
    "        artist_info = data['artists']['items'][0]\n",
    "        if artist_info['images']:\n",
    "            image_url = artist_info['images'][0]['url']\n",
    "            image_response = requests.get(image_url)\n",
    "            with open(f\"{folder}/{artist_name}.jpg\", 'wb') as f:\n",
    "                f.write(image_response.content)\n",
    "            print(f\"Album art for {artist_name} saved.\")\n",
    "        else:\n",
    "            print(f\"No album art found for {artist_name}.\")\n",
    "    else:\n",
    "        print(f\"No artist found for {artist_name}.\")\n",
    "\n",
    "def ensure_album_art(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Ensure album art for a given artist exists, either by checking locally or fetching from Spotify API.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check and save album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    if not check_album_art_exists(artist_name, folder):\n",
    "        token = get_spotify_access_token(SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET)\n",
    "        fetch_album_art(artist_name, token, folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spotify API Integration</h3>\n",
    "<strong>Get Spotify Access Token:</strong> Function to obtain Spotify access token using client credentials.\n",
    "\n",
    "<strong>Get Song Details:</strong> Function to retrieve song details from Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_access_token(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Get Spotify access token using client credentials.\n",
    "\n",
    "    This function sends a request to the Spotify API to get an access token \n",
    "    using the client credentials (client ID and client secret). The token is \n",
    "    required for further API requests.\n",
    "\n",
    "    Parameters:\n",
    "    client_id (str): The Spotify client ID.\n",
    "    client_secret (str): The Spotify client secret.\n",
    "\n",
    "    Returns:\n",
    "    str: The access token used for further API requests.\n",
    "    \"\"\"\n",
    "    auth_url = 'https://accounts.spotify.com/api/token'\n",
    "    auth_response = requests.post(auth_url, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "    \n",
    "    # Parse the authentication response and extract access token\n",
    "    auth_response_data = auth_response.json()\n",
    "    return auth_response_data['access_token']\n",
    "\n",
    "def get_song_details(artist_name, track_name, access_token):\n",
    "    \"\"\"\n",
    "    Get song details from Spotify API using search query.\n",
    "\n",
    "    This function sends a search request to the Spotify API using the given \n",
    "    artist name and track name. It retrieves detailed information about the \n",
    "    song including album, release date, popularity, duration, track number, \n",
    "    album artwork, external URLs, artists involved, and genres.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    track_name (str): The name of the track.\n",
    "    access_token (str): The Spotify API access token.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing detailed information about the song. \n",
    "          None if no track is found.\n",
    "    \"\"\"\n",
    "    search_url = 'https://api.spotify.com/v1/search'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    query = f'artist:{quote(artist_name)} track:{quote(track_name)}'\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'type': 'track',\n",
    "        'limit': 1\n",
    "    }\n",
    "    \n",
    "    # Send request to Spotify API to search for the track\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    response_data = response.json()\n",
    "    \n",
    "    \n",
    "    if 'tracks' in response_data and response_data['tracks']['items']:\n",
    "        track_info = response_data['tracks']['items'][0]\n",
    "        \n",
    "        # Get artist details to fetch genres in batches\n",
    "        artist_ids = [artist['id'] for artist in track_info['artists']]\n",
    "        artist_genres = []\n",
    "\n",
    "        batch_size = 50\n",
    "        for i in range(0, len(artist_ids), batch_size):\n",
    "            batch_ids = artist_ids[i:i + batch_size]\n",
    "            artist_url = f\"https://api.spotify.com/v1/artists?ids={','.join(batch_ids)}\"\n",
    "            retries = 5\n",
    "            delay = 1\n",
    "            \n",
    "            while retries > 0:\n",
    "                artist_response = requests.get(artist_url, headers=headers)\n",
    "                \n",
    "                if artist_response.status_code == 200:\n",
    "                    try:\n",
    "                        artist_data = artist_response.json()['artists']\n",
    "                        for artist in artist_data:\n",
    "                            if 'genres' in artist:\n",
    "                                artist_genres.extend(artist['genres'])\n",
    "                        break  # Exit the retry loop if successful\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error decoding JSON for batch {batch_ids}: {e}\")\n",
    "                elif artist_response.status_code == 429:\n",
    "                    retry_after = int(artist_response.headers.get('Retry-After', delay))\n",
    "                    print(f\"Rate limited. Retrying after {retry_after} seconds.\")\n",
    "                    time.sleep(retry_after)\n",
    "                else:\n",
    "                    print(f\"Request failed with status code {artist_response.status_code}\")\n",
    "                \n",
    "                retries -= 1\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "            \n",
    "            if retries == 0:\n",
    "                print(f\"Failed to fetch genres for batch {batch_ids} after {retries} attempts.\")\n",
    "        \n",
    "        # Ensure the genres list is ordered and unique\n",
    "        artist_genres = sorted(set(artist_genres))\n",
    "        \n",
    "        # Check if album images and external URLs are present\n",
    "        album_artwork = track_info['album']['images'][0]['url'] if 'images' in track_info['album'] and track_info['album']['images'] else None\n",
    "        external_urls = track_info['external_urls']['spotify'] if 'external_urls' in track_info else None\n",
    "        \n",
    "        song_details = {\n",
    "            'spotify_id': track_info['id'],\n",
    "            'album': track_info['album']['name'],\n",
    "            'release_date': track_info['album']['release_date'],\n",
    "            'popularity': track_info['popularity'],\n",
    "            'duration_ms': track_info['duration_ms'],\n",
    "            'track_number': track_info['track_number'],\n",
    "            'album_artwork': album_artwork,\n",
    "            'external_urls': external_urls,\n",
    "            'artists_involved': [artist['name'] for artist in track_info['artists']],\n",
    "            'genres': artist_genres\n",
    "        }\n",
    "        \n",
    "        print(\"Song details:\", song_details)\n",
    "        return song_details\n",
    "    else:\n",
    "        print(\"No tracks found for the given query.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multi-Threading for Data Processing</h3>\n",
    "<strong>Worker Thread:</strong> Function for worker threads to process each song in the queue.\n",
    "\n",
    "<strong>Update Unique Songs:</strong> Function to update the unique songs table with Spotify information using threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_thread(queue, unique_songs, unique_songs_file, access_token, export_interval, lock, start_time):\n",
    "    \"\"\"\n",
    "    Worker function to process each song in the queue.\n",
    "\n",
    "    This function processes each song in the queue by fetching song details \n",
    "    from the Spotify API and updating the unique songs DataFrame. It also \n",
    "    periodically exports the updated DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    queue (Queue): The queue containing songs to be processed.\n",
    "    unique_songs (DataFrame): The DataFrame of unique songs.\n",
    "    unique_songs_file (str): The file path for the unique songs CSV.\n",
    "    access_token (str): The Spotify API access token.\n",
    "    export_interval (int): The interval at which the DataFrame is exported to the CSV file.\n",
    "    lock (Lock): The lock to ensure thread-safe operations.\n",
    "    start_time (float): The start time of the processing.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    while not queue.empty():\n",
    "        index, row = queue.get()\n",
    "        if pd.notna(row['spotify_id']):\n",
    "            queue.task_done()\n",
    "            continue\n",
    "        \n",
    "        artist_name = row['artistName']\n",
    "        track_name = row['trackName']\n",
    "        song_details = get_song_details(artist_name, track_name, access_token)\n",
    "        \n",
    "        if song_details:\n",
    "            with lock:\n",
    "                unique_songs.at[index, 'spotify_id'] = song_details['spotify_id']\n",
    "                unique_songs.at[index, 'album'] = song_details['album']\n",
    "                unique_songs.at[index, 'release_date'] = song_details['release_date']\n",
    "                unique_songs.at[index, 'popularity'] = song_details['popularity']\n",
    "                unique_songs.at[index, 'duration_ms'] = song_details['duration_ms']\n",
    "                unique_songs.at[index, 'track_number'] = song_details['track_number']\n",
    "                unique_songs.at[index, 'album_artwork'] = song_details['album_artwork']\n",
    "                unique_songs.at[index, 'external_urls'] = song_details['external_urls']\n",
    "                unique_songs.at[index, 'artists_involved'] = song_details['artists_involved']\n",
    "                unique_songs.at[index, 'genres'] = song_details['genres']\n",
    "        \n",
    "        if (index + 1) % export_interval == 0:\n",
    "            with lock:\n",
    "                print(f\"Exporting data at index {index}. Elapsed time: {time.time() - start_time:.2f} seconds.\")\n",
    "                unique_songs.to_csv(unique_songs_file, index=False)\n",
    "        \n",
    "        queue.task_done()\n",
    "\n",
    "def update_unique_songs(unique_songs_file='unique_songs.csv', export_interval=50):\n",
    "    \"\"\"\n",
    "    Main function to update unique songs table with Spotify info using threading.\n",
    "\n",
    "    This function loads the unique songs data, checks for missing columns, and \n",
    "    updates the table with Spotify information using multiple threads. The \n",
    "    updated table is periodically exported to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path for the unique songs CSV. Defaults to 'unique_songs.csv'.\n",
    "    export_interval (int, optional): The interval at which the DataFrame is exported to the CSV file. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load unique songs data from CSV file\n",
    "    print(f\"Loading unique songs from {unique_songs_file}\")\n",
    "    unique_songs = pd.read_csv(unique_songs_file)\n",
    "    print(f\"Loaded {len(unique_songs)} unique songs\")\n",
    "\n",
    "    # Check if the columns already exist, if not, create them\n",
    "    columns = ['spotify_id', 'album', 'release_date', 'popularity', 'duration_ms', 'track_number', 'album_artwork', 'external_urls', 'artists_involved', 'genre']\n",
    "    for column in columns:\n",
    "        if column not in unique_songs.columns:\n",
    "            unique_songs[column] = None\n",
    "\n",
    "    # Get Spotify access token\n",
    "    access_token = get_spotify_access_token(SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET)\n",
    "    \n",
    "    # Create a queue and add songs to be processed\n",
    "    q = queue.Queue()\n",
    "    for index, row in unique_songs.iterrows():\n",
    "        q.put((index, row))\n",
    "\n",
    "    # Create a lock for thread-safe operations\n",
    "    lock = threading.Lock()\n",
    "    start_time = time.time()\n",
    "    threads = []\n",
    "    for _ in range(10):  # Adjust number of threads as needed\n",
    "        thread = threading.Thread(target=worker_thread, args=(q, unique_songs, unique_songs_file, access_token, export_interval, lock, start_time))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    \n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    # Remove duplicates based on 'external_urls'\n",
    "    unique_songs = drop_duplicates_by_external_urls(unique_songs)\n",
    "    \n",
    "    # Final export\n",
    "    print(f\"Final export. Total time taken: {time.time() - start_time:.2f} seconds.\")\n",
    "    unique_songs.to_csv(unique_songs_file, index=False)\n",
    "    print(f\"Unique songs table updated with Spotify info and saved to {unique_songs_file}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Deduplication and Filling</h3>\n",
    "<strong>Drop Duplicates:</strong> Function to drop duplicate songs based on external URLs.\n",
    "\n",
    "<strong>Fill Song Info:</strong> Function to fill in song information from the unique songs database.\n",
    "\n",
    "<strong>Read Processed Data:</strong> Function to read processed listening data.\n",
    "\n",
    "<strong>Export Filled Data:</strong> Function to export filled listening data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates_by_external_urls(data):\n",
    "    \"\"\"\n",
    "    This function drops duplicate rows based on the 'external_urls' column, \n",
    "    but retains rows where 'external_urls' is blank.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing the song data with 'external_urls' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed based on 'external_urls'.\n",
    "    \"\"\"\n",
    "    # Identify rows where external_urls is not blank\n",
    "    non_blank_urls = data['external_urls'].notna()\n",
    "    \n",
    "    # Drop duplicates only where external_urls is not blank\n",
    "    data_non_blank = data[non_blank_urls].drop_duplicates(subset=['external_urls'])\n",
    "    \n",
    "    # Combine the non-duplicated rows with the rows where external_urls is blank\n",
    "    data_final = pd.concat([data_non_blank, data[~non_blank_urls]], ignore_index=True)\n",
    "    \n",
    "    return data_final\n",
    "\n",
    "def fill_song_info(listening_data, unique_songs):\n",
    "    \"\"\"\n",
    "    Fill in song information from the unique songs database.\n",
    "\n",
    "    This function filters out rows with 'unknown' artists in the listening data,\n",
    "    then merges the listening data with the unique songs database on 'artistName'\n",
    "    and 'trackName' to fill in additional song information.\n",
    "\n",
    "    Parameters:\n",
    "    listening_data (pandas.DataFrame): DataFrame containing the user's listening data.\n",
    "    unique_songs (pandas.DataFrame): DataFrame containing the unique songs database.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with filled in song information.\n",
    "    \"\"\"\n",
    "    # Filter out rows where artistName is 'unknown'\n",
    "    listening_data_filtered = listening_data[~listening_data['artistName'].str.lower().isin(['unknown', 'unknown artist'])]\n",
    "    # Merge listening data with unique songs data on 'artistName' and 'trackName'\n",
    "    filled_data = pd.merge(listening_data_filtered, unique_songs, on=['artistName', 'trackName'], how='left')\n",
    "    return filled_data\n",
    "\n",
    "def read_processed_data(user_id):\n",
    "    \"\"\"\n",
    "    Read processed listening data from a CSV file.\n",
    "\n",
    "    This function reads a CSV file containing the user's processed listening data\n",
    "    and returns it as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the user's processed listening data.\n",
    "    \"\"\"\n",
    "    csv_file = f'{user_id}_listening_data.csv'  # Example file path, adjust as needed\n",
    "    listening_data = pd.read_csv(csv_file)\n",
    "    return listening_data\n",
    "\n",
    "def export_filled_data(filled_data, user_id):\n",
    "    \"\"\"\n",
    "    Export filled listening data to a CSV file.\n",
    "\n",
    "    This function exports the provided DataFrame containing filled listening data\n",
    "    to a CSV file named with the user's ID.\n",
    "\n",
    "    Parameters:\n",
    "    filled_data (pandas.DataFrame): The DataFrame containing the filled listening data.\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    filled_csv_file = f'{user_id}_listening_data.csv'\n",
    "    filled_data.to_csv(filled_csv_file, index=False)\n",
    "    print(f\"Filled listening data exported to {filled_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Data Analysis & Visualization</h1></strong>\n",
    "<h3>Listening Time Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_listening_time_per_user(df):\n",
    "    \"\"\"\n",
    "    Calculate total listening time per user.\n",
    "\n",
    "    This function calculates the total listening time for each user by summing\n",
    "    the 'msPlayed' column grouped by 'user_id' and converting the time from\n",
    "    milliseconds to hours.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'user_id' and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening time per user in hours.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    total_time = df_copy.groupby('user_id')['msPlayed'].sum()\n",
    "    total_time_hours = total_time / (1000 * 60 * 60)  # Convert milliseconds to hours\n",
    "    return total_time_hours\n",
    "\n",
    "\n",
    "def biggest_listening_date(df):\n",
    "    \"\"\"\n",
    "    Identify the biggest listening date and the total minutes listened to on that date.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the data by date,\n",
    "    sums the listening time ('msPlayed') for each date, and identifies the date with\n",
    "    the highest total listening time and the total listening time in minutes.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the biggest listening date and the total listening time on that date in minutes.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    \n",
    "    # Group by date and calculate the total listening time in milliseconds\n",
    "    total_listening_time_per_date = df_copy.groupby(df_copy['endTime'].dt.date)['msPlayed'].sum()\n",
    "    \n",
    "    # Identify the date with the highest total listening time\n",
    "    biggest_date = total_listening_time_per_date.idxmax()\n",
    "    \n",
    "    # Calculate the total listening time on that date in minutes\n",
    "    total_minutes_on_biggest_date = total_listening_time_per_date.max() / (1000 * 60)\n",
    "    \n",
    "    return biggest_date, total_minutes_on_biggest_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unique_counts(df):\n",
    "    \"\"\"\n",
    "    Calculate the number of unique songs, artists (using the expanded method), and albums.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with counts of unique songs, artists, and albums.\n",
    "    \"\"\"\n",
    "    print(\"Calculating unique counts\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    # Unique songs\n",
    "    unique_songs = df_copy['trackName'].nunique()\n",
    "\n",
    "    # Expand artists involved and calculate unique artists\n",
    "    df_copy = expand_artists_involved(df_copy)\n",
    "    unique_artists = df_copy['standardized_artists'].explode().nunique()\n",
    "\n",
    "    # Unique albums\n",
    "    unique_albums = df_copy['album'].nunique()\n",
    "\n",
    "    return {\n",
    "        'unique_songs': unique_songs,\n",
    "        'unique_artists': unique_artists,\n",
    "        'unique_albums': unique_albums\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Artist Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_artists_by_time(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate top listened-to artists by listening time.\n",
    "\n",
    "    This function expands the artists involved in each track, calculates the total\n",
    "    listening time for each artist by summing the 'msPlayed' column grouped by \n",
    "    'standardized_artists', and returns the top N artists based on their total \n",
    "    listening time, converted to seconds.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'standardized_artists' and 'msPlayed' columns.\n",
    "    top_n (int, optional): Number of top artists to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening time per artist in seconds, sorted in descending order.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_expanded = df_copy.explode('standardized_artists')\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to original artists\n",
    "    original_artists_dict = df_expanded.set_index('standardized_artists')['artistName'].to_dict()\n",
    "    \n",
    "    artist_time = df_expanded.groupby('standardized_artists')['msPlayed'].sum().sort_values(ascending=False).head(top_n)\n",
    "    \n",
    "    # Map the standardized artists back to the original artists\n",
    "    artist_time.index = artist_time.index.map(original_artists_dict)\n",
    "    \n",
    "    return artist_time\n",
    "\n",
    "\n",
    "def top_artists_by_count(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate top listened-to artists by count.\n",
    "\n",
    "    This function expands the artists involved in each track, calculates the count\n",
    "    of occurrences for each artist using the 'standardized_artists' column, and returns\n",
    "    the top N artists based on their count.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'standardized_artists' column.\n",
    "    top_n (int, optional): Number of top artists to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the count of occurrences per artist, sorted in descending order.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating top {top_n} artists by count\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_expanded = df_copy.explode('standardized_artists')\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = df_expanded.groupby('standardized_artists')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    artist_count = df_expanded['standardized_artists'].value_counts().head(top_n)\n",
    "    \n",
    "    # Map the standardized artists back to the most common original artists\n",
    "    artist_count.index = artist_count.index.map(original_artists_dict)\n",
    "    \n",
    "    return artist_count\n",
    "\n",
    "\n",
    "\n",
    "def top_artists_by_weighted_time(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate the top artists based on weighted listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing artist data.\n",
    "    top_n (int): Number of top artists to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the top artists by weighted listening time.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating top {top_n} artists by weighted listening time\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_expanded = df_copy.explode('standardized_artists')\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = df_expanded.groupby('standardized_artists')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    weighted_times = {}\n",
    "\n",
    "    for index, row in df_expanded.iterrows():\n",
    "        artist_name = row['artistName'].lower()\n",
    "        current_artist = row['standardized_artists']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        duration_ms = row['duration_ms']\n",
    "        \n",
    "        # Skip if percentage_listened or duration_ms is NaN\n",
    "        if pd.isna(percentage_listened) or pd.isna(duration_ms):\n",
    "            continue\n",
    "        \n",
    "        # Add check for empty or suspicious artist names\n",
    "        if not current_artist or not isinstance(current_artist, str):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        # Calculate actual listened time\n",
    "        listened_time = percentage_listened * duration_ms\n",
    "        \n",
    "        if artist_name in current_artist:\n",
    "            main_artist_weight = 0.5 * listened_time\n",
    "            other_artists_weight = 0.5 * listened_time / (len(row['artists_involved']) - 1) if len(row['artists_involved']) > 1 else 0\n",
    "            \n",
    "            # Add weight to main artist\n",
    "            if artist_name not in weighted_times:\n",
    "                weighted_times[artist_name] = 0\n",
    "            weighted_times[artist_name] += main_artist_weight\n",
    "            \n",
    "            # Add weight to other artists\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() != artist_name:\n",
    "                    if artist.lower() not in weighted_times:\n",
    "                        weighted_times[artist.lower()] = 0\n",
    "                    weighted_times[artist.lower()] += other_artists_weight\n",
    "        else:\n",
    "            equal_weight = listened_time / len(row['artists_involved'])\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() not in weighted_times:\n",
    "                    weighted_times[artist.lower()] = 0\n",
    "                weighted_times[artist.lower()] += equal_weight\n",
    "    \n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_times_df = pd.DataFrame.from_dict(weighted_times, orient='index', columns=['weighted_time'])\n",
    "    top_artists_weighted_time = weighted_times_df.sort_values(by='weighted_time', ascending=False).head(top_n)\n",
    "    \n",
    "    # Map the standardized artists back to the most common original artists\n",
    "    top_artists_weighted_time.index = top_artists_weighted_time.index.map(original_artists_dict)\n",
    "    \n",
    "    return top_artists_weighted_time\n",
    "\n",
    "def top_artists_by_weighted_count(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate the top artists based on weighted listen counts.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing artist data.\n",
    "    top_n (int): Number of top artists to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the top artists by weighted listens.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating top {top_n} artists by weighted listen counts\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_expanded = df_copy.explode('standardized_artists')\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = df_expanded.groupby('standardized_artists')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    weighted_listens = {}\n",
    "\n",
    "    for index, row in df_expanded.iterrows():\n",
    "        artist_name = row['artistName'].lower()\n",
    "        current_artist = row['standardized_artists']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        \n",
    "        # Skip if percentage_listened is NaN\n",
    "        if pd.isna(percentage_listened):\n",
    "            continue\n",
    "        \n",
    "        # Add check for empty or suspicious artist names\n",
    "        if not current_artist or not isinstance(current_artist, str):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        if artist_name in current_artist:\n",
    "            main_artist_weight = 0.5 * percentage_listened\n",
    "            other_artists_weight = 0.5 * percentage_listened / (len(row['artists_involved']) - 1) if len(row['artists_involved']) > 1 else 0\n",
    "            \n",
    "            # Add weight to main artist\n",
    "            if artist_name not in weighted_listens:\n",
    "                weighted_listens[artist_name] = 0\n",
    "            weighted_listens[artist_name] += main_artist_weight\n",
    "            \n",
    "            # Add weight to other artists\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() != artist_name:\n",
    "                    if artist.lower() not in weighted_listens:\n",
    "                        weighted_listens[artist.lower()] = 0\n",
    "                    weighted_listens[artist.lower()] += other_artists_weight\n",
    "        else:\n",
    "            equal_weight = percentage_listened / len(row['artists_involved'])\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() not in weighted_listens:\n",
    "                    weighted_listens[artist.lower()] = 0\n",
    "                weighted_listens[artist.lower()] += equal_weight\n",
    "    \n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_listens_df = pd.DataFrame.from_dict(weighted_listens, orient='index', columns=['weighted_listens'])\n",
    "    top_artists_weighted_listens = weighted_listens_df.sort_values(by='weighted_listens', ascending=False).head(top_n)\n",
    "    \n",
    "    # Map the standardized artists back to the most common original artists\n",
    "    top_artists_weighted_listens.index = top_artists_weighted_listens.index.map(original_artists_dict)\n",
    "    \n",
    "    return top_artists_weighted_listens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_artists_by_genre(df, genre, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify top artists within a specific genre.\n",
    "\n",
    "    This function filters the DataFrame by genre, sums the listening time ('minutesPlayed') for each artist,\n",
    "    and identifies the top artists within the genre based on the listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'genres', 'artistName', and 'msPlayed' columns.\n",
    "    genre (str): The genre to filter by.\n",
    "    top_n (int, optional): Number of top artists to return for the specified genre. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    list: List of the top artists within the specified genre based on listening time.\n",
    "    \"\"\"\n",
    "    print(f\"analyzing top artists for genre: {genre}\")\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_genre = df[df['genres'].apply(lambda x: genre in x)]\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_genre['minutesPlayed'] = df_genre['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    top_artists = df_genre.groupby('artistName')['minutesPlayed'].sum().nlargest(top_n).index.tolist()\n",
    "    return top_artists\n",
    "\n",
    "\n",
    "def artist_attention_span(df):\n",
    "    \"\"\"\n",
    "    Calculate the attention span for different artists.\n",
    "\n",
    "    This function calculates the average percentage of each track listened to before skipping for each artist,\n",
    "    capping the percentage at 100 if it exceeds 100. It also returns the total listening time for each artist.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'artistName', 'duration_ms', and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Series containing the average percentage of tracks listened to for each artist, and a Series with the total listening time for each artist in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating music taste attention span for artists\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    # Cap the percentage_listened values at 100\n",
    "    df_copy['percentage_listened'] = df_copy['percentage_listened'].apply(lambda x: min(x, 100))\n",
    "    \n",
    "    valid_entries = df_copy.dropna(subset=['duration_ms', 'percentage_listened'])\n",
    "    \n",
    "    # Ensure standardized_artists is a string\n",
    "    valid_entries['standardized_artists_str'] = valid_entries['standardized_artists'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = valid_entries.groupby('standardized_artists_str')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    # Calculate average percentage listened for each artist\n",
    "    artist_span = valid_entries.groupby('standardized_artists_str')['percentage_listened'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Map the standardized artists back to the most common original artists\n",
    "    artist_span.index = artist_span.index.map(original_artists_dict)\n",
    "    \n",
    "    # Calculate total listening time for each artist\n",
    "    valid_entries.loc[:, 'listened_time'] = valid_entries['duration_ms'] * (valid_entries['percentage_listened'] / 100)\n",
    "    artist_listened_time = valid_entries.groupby('standardized_artists_str')['listened_time'].sum() / (1000 * 60)  # Convert milliseconds to minutes\n",
    "    \n",
    "    # Map the standardized artists back to the most common original artists\n",
    "    artist_listened_time.index = artist_listened_time.index.map(original_artists_dict)\n",
    "    \n",
    "    return artist_span, artist_listened_time\n",
    "\n",
    "def artist_diversity_growth(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Calculate the growth in artist diversity over a period of time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month, and calculates the percentage growth in the number of distinct artists listened to between each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'standardized_artists' columns.\n",
    "    distinguish_years (bool, optional): Whether to distinguish between months of different years. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the percentage growth in distinct artists per month.\n",
    "    \"\"\"\n",
    "    print(\"Calculating artist diversity growth\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_expanded = df_copy.explode('standardized_artists')\n",
    "    \n",
    "    # Ensure standardized_artists is a string\n",
    "    df_expanded['standardized_artists_str'] = df_expanded['standardized_artists'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = df_expanded.groupby('standardized_artists_str')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    if distinguish_years:\n",
    "        df_expanded['year_month'] = df_expanded['endTime'].dt.to_period('M')\n",
    "        artist_diversity = df_expanded.groupby('year_month')['standardized_artists_str'].nunique()\n",
    "    else:\n",
    "        df_expanded['month'] = df_expanded['endTime'].dt.month\n",
    "        artist_diversity = df_expanded.groupby('month')['standardized_artists_str'].nunique()\n",
    "    \n",
    "    artist_diversity_growth = artist_diversity.pct_change().fillna(0) * 100\n",
    "    \n",
    "    if not distinguish_years:\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        artist_diversity_growth.index = artist_diversity_growth.index.map(month_names)\n",
    "\n",
    "    return artist_diversity_growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "def top_collaborating_artists(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Identify the top collaborating artists based on the 'artists_involved' column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'artists_involved' column.\n",
    "    top_n (int): Number of top collaborating artist pairs to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the top collaborating artist pairs and their collaboration counts.\n",
    "    \"\"\"\n",
    "    print(\"Identifying top collaborating artists\")\n",
    "\n",
    "    def normalize_name(name):\n",
    "        \"\"\" Normalize the artist name to a standard format. \"\"\"\n",
    "        return name.strip().lower()\n",
    "    \n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    print(df_copy['artists_involved'])\n",
    "    df_copy['artists_involved'] = df_copy['artists_involved'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Create pairs of collaborating artists\n",
    "    pairs = []\n",
    "    for artists in df_copy['artists_involved']:\n",
    "        if len(artists) > 1:\n",
    "            for pair in combinations(artists, 2):\n",
    "                pairs.append(pair)\n",
    "    \n",
    "    # Count collaborations\n",
    "    pair_counts = Counter(pairs)\n",
    "    \n",
    "    # Map back to original names and normalize\n",
    "    original_pairs = []\n",
    "    for pair, count in pair_counts.items():\n",
    "        normalized_pair = tuple(sorted(normalize_name(artist) for artist in pair))\n",
    "        original_pair = tuple(pair)\n",
    "        original_pairs.append((original_pair, count))\n",
    "    \n",
    "    top_collaborating_artists_df = pd.DataFrame(original_pairs, columns=['artist_pair', 'collaboration_count']).sort_values(by='collaboration_count', ascending=False).head(top_n)\n",
    "    \n",
    "    # Debug print: Check the final DataFrame\n",
    "    print(\"Top collaborating artists DataFrame:\", top_collaborating_artists_df)\n",
    "    \n",
    "    return top_collaborating_artists_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Music Taste and Habits Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def top_weighted_artists_per_month(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Analyze top 5 weighted artists per month, with an option to distinguish between years.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month and artist, calculates the weighted listening time ('msPlayed' * 'percentage_listened'), and identifies the top 5 artists per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'artistName', 'artists_involved', 'msPlayed', and 'percentage_listened' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months (and optionally years) as keys and lists of the top 5 artists for each month by weighted listening time.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing top weighted artists per month\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['artists_involved'] = df_copy['artists_involved'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_artists(artists):\n",
    "        try:\n",
    "            return literal_eval(artists)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df_copy['artists_involved'] = df_copy['artists_involved'].apply(parse_artists)\n",
    "    df_copy['weighted_listening_time'] = df_copy['msPlayed'] * df_copy['percentage_listened'] / 100\n",
    "    \n",
    "    def add_main_artist(row):\n",
    "        if row['artistName'] not in row['artists_involved']:\n",
    "            row['artists_involved'].append(row['artistName'])\n",
    "        return row\n",
    "    \n",
    "    df_copy = df_copy.apply(add_main_artist, axis=1)\n",
    "    df_expanded = df_copy.explode('artists_involved')\n",
    "    \n",
    "    # Ensure artists_involved is a string\n",
    "    df_expanded['artists_involved_str'] = df_expanded['artists_involved'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    # Create a dictionary to map standardized artists to the most common original artist name\n",
    "    original_artists_dict = df_expanded.groupby('artists_involved_str')['artistName'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "    \n",
    "    top_artists_per_month = {}\n",
    "    if distinguish_years:\n",
    "        df_expanded['year_month'] = df_expanded['endTime'].dt.to_period('M')\n",
    "        for period in df_expanded['year_month'].unique():\n",
    "            monthly_df = df_expanded[df_expanded['year_month'] == period]\n",
    "            top_artists = monthly_df.groupby('artists_involved_str')['weighted_listening_time'].sum().nlargest(5)\n",
    "            top_artists_per_month[period] = top_artists.index.tolist()\n",
    "        formatted_output = {period.strftime('%B %Y'): [original_artists_dict[artist] for artist in artists] for period, artists in top_artists_per_month.items()}\n",
    "    else:\n",
    "        for month in df_expanded['endTime'].dt.month.unique():\n",
    "            monthly_df = df_expanded[df_expanded['endTime'].dt.month == month]\n",
    "            top_artists = monthly_df.groupby('artists_involved_str')['weighted_listening_time'].sum().nlargest(5)\n",
    "            top_artists_per_month[month] = top_artists.index.tolist()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        formatted_output = {month_names[month]: [original_artists_dict[artist] for artist in artists] for month, artists in top_artists_per_month.items()}\n",
    "\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "\n",
    "def top_songs_by_plays_per_month(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Analyze top 5 songs by unweighted plays per month, with an option to distinguish between years.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups by month (and optionally year) and track,\n",
    "    counts the number of plays for each track, and identifies the top 5 songs per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'trackName' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months (and optionally years) as keys and lists of the top 5 tracks for each month by unweighted plays.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing top songs by unweighted plays per month\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    \n",
    "    top_songs_per_month = {}\n",
    "    if distinguish_years:\n",
    "        df_copy['year_month'] = df_copy['endTime'].dt.to_period('M')\n",
    "        for period in df_copy['year_month'].unique():\n",
    "            monthly_df = df_copy[df_copy['year_month'] == period]\n",
    "            top_songs = monthly_df['trackName'].value_counts().nlargest(5)\n",
    "            top_songs_per_month[period] = top_songs.index.tolist()\n",
    "        formatted_output = {period.strftime('%B %Y'): songs for period, songs in top_songs_per_month.items()}\n",
    "    else:\n",
    "        for month in df_copy['endTime'].dt.month.unique():\n",
    "            monthly_df = df_copy[df_copy['endTime'].dt.month == month]\n",
    "            top_songs = monthly_df['trackName'].value_counts().nlargest(5)\n",
    "            top_songs_per_month[month] = top_songs.index.tolist()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        formatted_output = {month_names[month]: songs for month, songs in top_songs_per_month.items()}\n",
    "\n",
    "    return formatted_output\n",
    "\n",
    "def top_songs_by_weighted_time_per_month(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Analyze top 5 songs by weighted listening time per month, with an option to distinguish between years.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month and track, calculates the weighted listening time ('msPlayed' * 'percentage_listened'), and identifies the top 5 songs per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', 'msPlayed', and 'percentage_listened' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months (and optionally years) as keys and lists of the top 5 tracks for each month by weighted listening time.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing top songs by weighted listening time per month\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['weighted_listening_time'] = df_copy['msPlayed'] * df_copy['percentage_listened'] / 100\n",
    "    \n",
    "    top_songs_per_month = {}\n",
    "    if distinguish_years:\n",
    "        df_copy['year_month'] = df_copy['endTime'].dt.to_period('M')\n",
    "        for period in df_copy['year_month'].unique():\n",
    "            monthly_df = df_copy[df_copy['year_month'] == period]\n",
    "            top_songs = monthly_df.groupby('trackName')['weighted_listening_time'].sum().nlargest(5)\n",
    "            top_songs_per_month[period] = top_songs.index.tolist()\n",
    "        formatted_output = {period.strftime('%B %Y'): songs for period, songs in top_songs_per_month.items()}\n",
    "    else:\n",
    "        for month in df_copy['endTime'].dt.month.unique():\n",
    "            monthly_df = df_copy[df_copy['endTime'].dt.month == month]\n",
    "            top_songs = monthly_df.groupby('trackName')['weighted_listening_time'].sum().nlargest(5)\n",
    "            top_songs_per_month[month] = top_songs.index.tolist()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        formatted_output = {month_names[month]: songs for month, songs in top_songs_per_month.items()}\n",
    "\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def monthly_listening_patterns(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Analyze monthly listening patterns, with an option to distinguish between years.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the DataFrame by month,\n",
    "    and calculates the total listening duration for each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'msPlayed' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening duration for each month in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating monthly listening patterns\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    \n",
    "    if distinguish_years:\n",
    "        df_copy['year_month'] = df_copy['endTime'].dt.to_period('M')\n",
    "        monthly_duration = df_copy.groupby('year_month')['msPlayed'].sum()\n",
    "        # Convert the period index to a string in \"Month Year\" format\n",
    "        monthly_duration.index = monthly_duration.index.strftime('%B %Y')\n",
    "    else:\n",
    "        df_copy['month'] = df_copy['endTime'].dt.month\n",
    "        monthly_duration = df_copy.groupby('month')['msPlayed'].sum()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        monthly_duration.index = monthly_duration.index.map(month_names)\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    monthly_duration = monthly_duration / (1000 * 60)\n",
    "    \n",
    "    return monthly_duration\n",
    "\n",
    "\n",
    "def track_listening_duration_over_time(df):\n",
    "    \"\"\"\n",
    "    Calculate the total listening duration for each track over different time periods.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the DataFrame by track and month,\n",
    "    and calculates the total listening duration for each track per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the total listening duration for each track per month in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating track listening duration over time\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    \n",
    "    # Group by track and month, and calculate total listening duration\n",
    "    df_copy['month'] = df_copy['endTime'].dt.to_period('M')\n",
    "    df_grouped = df_copy.groupby(['trackName', 'month'])['msPlayed'].sum().reset_index()\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_grouped['listening_duration_minutes'] = df_grouped['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    # Sort by 'month' first to ensure chronological order\n",
    "    df_grouped = df_grouped.sort_values(by='month')\n",
    "    df_grouped['month_str'] = df_grouped['month'].dt.strftime('%B %Y')\n",
    "\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def common_listening_days(df):\n",
    "    \"\"\"\n",
    "    Determine the most common listening days and times.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, calculates the frequency\n",
    "    of each day of the week in the listening data, and returns the counts of the most\n",
    "    common listening days.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' column.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the counts of the most common listening days.\n",
    "    \"\"\"\n",
    "    print(\"Determining the most common listening days and times\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    common_days = df_copy['endTime'].dt.day_name().value_counts()\n",
    "    return common_days\n",
    "\n",
    "\n",
    "\n",
    "def general_attention_span(df):\n",
    "    \"\"\"\n",
    "    Calculate the general attention span for all tracks.\n",
    "\n",
    "    This function calculates the average percentage of each track listened to before skipping,\n",
    "    capping the percentage at 100 if it exceeds 100. It also returns the count of times each song was listened to.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'duration_ms' and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    float: Average percentage of tracks listened to before skipping.\n",
    "    \"\"\"\n",
    "    print(\"Calculating general music taste attention span\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    \n",
    "    # Cap the percentage_listened values at 100\n",
    "    df_copy['percentage_listened'] = df_copy['percentage_listened'].apply(lambda x: min(x, 100))\n",
    "    \n",
    "    valid_entries = df_copy.dropna(subset=['duration_ms', 'percentage_listened'])\n",
    "    attention_span = valid_entries['percentage_listened'].mean()\n",
    "    \n",
    "    return attention_span\n",
    "\n",
    "\n",
    "def listening_percentage_categories(df):\n",
    "    \"\"\"\n",
    "    Categorize listening percentages into ranges and count occurrences.\n",
    "\n",
    "    This function categorizes the percentage of each track listened to before skipping\n",
    "    into ranges (0-24%, 25-49%, 50-74%, 75-100%) and counts the number of occurrences in each range.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'percentage_listened' column.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing the counts of occurrences in each range.\n",
    "    \"\"\"\n",
    "    print(\"Categorizing listening percentages into ranges\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    # Cap the percentage_listened values at 100\n",
    "    df_copy['percentage_listened'] = df_copy['percentage_listened'].apply(lambda x: min(x, 100))\n",
    "\n",
    "    valid_entries = df_copy.dropna(subset=['percentage_listened'])\n",
    "\n",
    "    # Define the ranges\n",
    "    bins = [0, 24, 49, 74, 100]\n",
    "    labels = ['0-24%', '25-49%', '50-74%', '75-100%']\n",
    "\n",
    "    # Categorize the percentages into bins\n",
    "    df_copy['listening_range'] = pd.cut(valid_entries['percentage_listened'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Count the occurrences in each range\n",
    "    range_counts = df_copy['listening_range'].value_counts().sort_index()\n",
    "\n",
    "    return range_counts.to_dict()\n",
    "\n",
    "\n",
    "def top_songs_by_listening_time(df, top_n=10, weighted=False):\n",
    "    \"\"\"\n",
    "    Get the top songs for the year by listening time.\n",
    "\n",
    "    This function calculates the top songs by listening time, either weighted or unweighted, for the specified number of top songs.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'trackName', 'msPlayed', and 'percentage_listened' columns.\n",
    "    top_n (int): Number of top songs to return. Default is 10.\n",
    "    weighted (bool): Whether to calculate weighted listening time.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the top songs and their listening times.\n",
    "    \"\"\"\n",
    "    print(\"Calculating top songs by listening time\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    weighted_times = {}\n",
    "\n",
    "    for index, row in df_copy.iterrows():\n",
    "        track_name = row['trackName']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        duration_ms = row['duration_ms']\n",
    "        \n",
    "        # Skip if percentage_listened or duration_ms is NaN\n",
    "        if pd.isna(percentage_listened) or pd.isna(duration_ms):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        if weighted:\n",
    "            # Calculate actual listened time\n",
    "            listened_time = percentage_listened * duration_ms\n",
    "        else:\n",
    "            # Calculate unweighted listening time\n",
    "            listened_time = duration_ms\n",
    "        \n",
    "        if track_name not in weighted_times:\n",
    "            weighted_times[track_name] = 0\n",
    "        weighted_times[track_name] += listened_time\n",
    "\n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_times_df = pd.DataFrame.from_dict(weighted_times, orient='index', columns=['listening_time'])\n",
    "    top_songs_listening_time = weighted_times_df.sort_values(by='listening_time', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_songs_listening_time\n",
    "\n",
    "\n",
    "def top_songs_by_listen_totals(df, top_n=10, weighted=False):\n",
    "    \"\"\"\n",
    "    Get the top songs for the year by listen totals.\n",
    "\n",
    "    This function calculates the top songs by listen totals, either weighted or unweighted, for the specified number of top songs.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'trackName' and 'percentage_listened' columns.\n",
    "    top_n (int): Number of top songs to return. Default is 10.\n",
    "    weighted (bool): Whether to calculate weighted listen totals.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the top songs and their listen totals.\n",
    "    \"\"\"\n",
    "    print(\"Calculating top songs by listen totals\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "\n",
    "    weighted_listens = {}\n",
    "\n",
    "    for index, row in df_copy.iterrows():\n",
    "        track_name = row['trackName']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        \n",
    "        # Skip if percentage_listened is NaN\n",
    "        if pd.isna(percentage_listened):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        if weighted:\n",
    "            if track_name not in weighted_listens:\n",
    "                weighted_listens[track_name] = 0\n",
    "            weighted_listens[track_name] += percentage_listened\n",
    "        else:\n",
    "            if track_name not in weighted_listens:\n",
    "                weighted_listens[track_name] = 0\n",
    "            weighted_listens[track_name] += 1\n",
    "\n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_listens_df = pd.DataFrame.from_dict(weighted_listens, orient='index', columns=['listen_totals'])\n",
    "    top_songs_listen_totals = weighted_listens_df.sort_values(by='listen_totals', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_songs_listen_totals\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Genre Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_genres_per_month(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Analyze top genres per month, with an option to distinguish between years.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month (and optionally year) and genre, and sums the listening time ('minutesPlayed') for each genre.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'genres', and 'msPlayed' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months (and optionally years) as keys and lists of the top genres for each month.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top genres per month\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['genres'] = df_copy['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    df_expanded = df_copy.explode('genres')\n",
    "    \n",
    "    df_expanded['minutesPlayed'] = df_expanded['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    top_genres_per_month = {}\n",
    "    if distinguish_years:\n",
    "        df_expanded['year_month'] = df_expanded['endTime'].dt.to_period('M')\n",
    "        for period in df_expanded['year_month'].unique():\n",
    "            monthly_df = df_expanded[df_expanded['year_month'] == period]\n",
    "            top_genres = monthly_df.groupby('genres')['minutesPlayed'].sum().nlargest(5)\n",
    "            top_genres_per_month[period] = top_genres.index.tolist()\n",
    "        formatted_output = {str(period): genres for period, genres in top_genres_per_month.items()}\n",
    "    else:\n",
    "        df_expanded['month'] = df_expanded['endTime'].dt.month\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        for month in df_expanded['month'].unique():\n",
    "            monthly_df = df_expanded[df_expanded['month'] == month]\n",
    "            top_genres = monthly_df.groupby('genres')['minutesPlayed'].sum().nlargest(5)\n",
    "            top_genres_per_month[month_names[month]] = top_genres.index.tolist()\n",
    "        formatted_output = {month: genres for month, genres in top_genres_per_month.items()}\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def top_genres_for_year(df, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify the top genres for the year.\n",
    "\n",
    "    This function calculates the frequency of each genre and returns the top genres along with their total listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'genres' and 'msPlayed' columns.\n",
    "    top_n (int): Number of top genres to return. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the top genres and their total listening times.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top genres for the year\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['genres'] = df_copy['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        \"\"\"\n",
    "        Parse the genres column to ensure it contains valid genre data.\n",
    "\n",
    "        Args:\n",
    "            genres (str or list): The genre data to parse.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of genres.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ast.literal_eval(genres) if isinstance(genres, str) else genres\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    df_expanded = df_copy.explode('genres')\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_expanded['minutesPlayed'] = df_expanded['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    # Calculate total listening time per genre and get the top genres\n",
    "    genre_taste = df_expanded.groupby('genres')['minutesPlayed'].sum().nlargest(top_n)\n",
    "    \n",
    "    # Ensure the index (genre names) are strings\n",
    "    genre_taste.index = genre_taste.index.astype(str)\n",
    "    \n",
    "    return genre_taste\n",
    "\n",
    "\n",
    "def top_tracks_by_genre(df, genre, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify top tracks within a specific genre.\n",
    "\n",
    "    This function filters the DataFrame by genre, sums the listening time ('minutesPlayed') for each track,\n",
    "    and identifies the top tracks within the genre based on the listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', 'msPlayed', and 'genres' columns.\n",
    "    genre (str): The genre to filter by.\n",
    "    top_n (int): Number of top tracks to return for the specified genre. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: List of tuples containing the top tracks within the specified genre and their corresponding listening times in minutes.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing top tracks for genre: {genre}\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        \"\"\"\n",
    "        Parse the genres column to ensure it contains valid genre data.\n",
    "\n",
    "        Args:\n",
    "            genres (str or list): The genre data to parse.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of genres.\n",
    "        \"\"\"\n",
    "        if isinstance(genres, list):\n",
    "            return genres\n",
    "        if pd.isna(genres) or genres == '[]':\n",
    "            return []\n",
    "        try:\n",
    "            # If genres is a string representation of a list\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    # Parse genres\n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    \n",
    "    df_genre = df_copy[df_copy['genres'].apply(lambda x: genre in x)]\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_genre['minutesPlayed'] = df_genre['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    top_tracks = df_genre.groupby('trackName')['minutesPlayed'].sum().nlargest(top_n)\n",
    "    \n",
    "    return list(top_tracks.items())\n",
    "\n",
    "\n",
    "\n",
    "def top_tracks_by_top_genres(df, top_genres, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify top tracks for each of the top genres.\n",
    "\n",
    "    This function loops through the specified top genres, calls the top_tracks_by_genre function,\n",
    "    and formats the top tracks for each genre.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data.\n",
    "    top_genres (list): List of top genres to analyze.\n",
    "    top_n (int): Number of top tracks to return for each genre. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    str: Formatted string containing the top tracks for each genre.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store formatted tracks by genre\n",
    "    formatted_genre_tracks = []\n",
    "\n",
    "    # Loop through the top genres and get the top tracks for each\n",
    "    for genre in top_genres:\n",
    "        top_tracks_genre = top_tracks_by_genre(df, genre, top_n)\n",
    "        \n",
    "        formatted_tracks = []\n",
    "        for track, minutes in top_tracks_genre:\n",
    "            formatted_tracks.append(f\"{track} - {minutes:.2f} min.\")\n",
    "        formatted_tracks = \"<br/>\".join(formatted_tracks)\n",
    "        formatted_genre_tracks.append(f\"<b>Top Tracks in {genre.title()}:</b><br/>{formatted_tracks}\")\n",
    "\n",
    "    # Combine all the formatted tracks by genre into a single string\n",
    "    formatted_genre_tracks = \"<br/><br/>\".join(formatted_genre_tracks)\n",
    "\n",
    "    return formatted_genre_tracks\n",
    "\n",
    "\n",
    "def genre_popularity_over_time(df):\n",
    "    \"\"\"\n",
    "    Analyze genre popularity over time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by date and genre, and sums the listening time ('msPlayed') in minutes for each genre.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'genres', and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing genre popularity over time\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['genres'] = df_copy['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    df_expanded = df_copy.explode('genres')\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_expanded['minutesPlayed'] = df_expanded['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    genre_popularity = df_expanded.groupby([df_expanded['endTime'].dt.date, 'genres'])['minutesPlayed'].sum().unstack().fillna(0)\n",
    "    \n",
    "    return genre_popularity\n",
    "\n",
    "\n",
    "def summarize_genre_popularity(genre_popularity_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Summarize genre popularity over time.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity_df (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    top_n (int): Number of top genres to summarize.\n",
    "\n",
    "    Returns:\n",
    "    str: Summary of key insights into genre popularity.\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    \n",
    "    if genre_popularity_df.empty:\n",
    "        return \"No data available to summarize genre popularity.\"\n",
    "\n",
    "    # Identify overall top genres\n",
    "    total_listening = genre_popularity_df.sum()\n",
    "    top_genres = total_listening.nlargest(top_n).index\n",
    "    summary.append(f\"Top {top_n} genres over the period: \" + \", \".join(top_genres))\n",
    "    \n",
    "    # Ensure there are enough rows to access the first and last elements\n",
    "    if len(genre_popularity_df) > 1:\n",
    "        # Determine any significant changes in genre popularity\n",
    "        most_recent = genre_popularity_df.iloc[-1][top_genres]\n",
    "        initial = genre_popularity_df.iloc[0][top_genres]\n",
    "        changes = (most_recent - initial) / initial * 100\n",
    "        significant_changes = changes[abs(changes) > 50]\n",
    "        \n",
    "        if not significant_changes.empty:\n",
    "            summary.append(\"Significant changes in genre popularity:\")\n",
    "            for genre, change in significant_changes.items():\n",
    "                direction = \"increased\" if change > 0 else \"decreased\"\n",
    "                summary.append(f\"{genre.title()}: {direction} by {abs(change):.2f}%\")\n",
    "        else:\n",
    "            summary.append(\"No significant changes in genre popularity.\")\n",
    "    else:\n",
    "        summary.append(\"Insufficient data to determine significant changes in genre popularity.\")\n",
    "    \n",
    "    return \"<br/>\".join(summary)\n",
    "\n",
    "\n",
    "\n",
    "def genre_diversity_per_month(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Calculate the diversity of user's music taste per month based on the number of distinct genres.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month (and optionally year) and counts the number of distinct genres listened to each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'genres' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the count of distinct genres per month.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing genre diversity per month\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['genres'] = df_copy['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        \"\"\"\n",
    "        Parse the genres column to ensure it contains valid genre data.\n",
    "\n",
    "        Args:\n",
    "            genres (str or list): The genre data to parse.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of genres.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    df_expanded = df_copy.explode('genres')\n",
    "    \n",
    "    if distinguish_years:\n",
    "        df_expanded['year_month'] = df_expanded['endTime'].dt.to_period('M')\n",
    "        genre_diversity = df_expanded.groupby('year_month')['genres'].nunique()\n",
    "    else:\n",
    "        df_expanded['month'] = df_expanded['endTime'].dt.month\n",
    "        genre_diversity = df_expanded.groupby('month')['genres'].nunique()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        genre_diversity.index = genre_diversity.index.map(month_names)\n",
    "    \n",
    "    return genre_diversity\n",
    "\n",
    "def genre_diversity_growth(df, distinguish_years=True):\n",
    "    \"\"\"\n",
    "    Calculate the growth in genre diversity over a period of time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month (and optionally year), and calculates the percentage growth in the number of distinct genres listened to between each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'genres' columns.\n",
    "    distinguish_years (bool): Whether to distinguish between months of different years.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the percentage growth in distinct genres per month.\n",
    "    \"\"\"\n",
    "    print(\"Calculating genre diversity growth\")\n",
    "    df_copy = df.copy()  # Copy the DataFrame to avoid modifying the original\n",
    "    df_copy['endTime'] = pd.to_datetime(df_copy['endTime'])\n",
    "    df_copy['genres'] = df_copy['genres'].replace({pd.NA: '[]'})\n",
    "\n",
    "    def parse_genres(genres):\n",
    "        \"\"\"\n",
    "        Parse the genres column to ensure it contains valid genre data.\n",
    "\n",
    "        Args:\n",
    "            genres (str or list): The genre data to parse.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of genres.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    df_copy['genres'] = df_copy['genres'].apply(parse_genres)\n",
    "    df_expanded = df_copy.explode('genres')\n",
    "\n",
    "    if distinguish_years:\n",
    "        df_expanded['year_month'] = df_expanded['endTime'].dt.to_period('M')\n",
    "        genre_diversity = df_expanded.groupby('year_month')['genres'].nunique()\n",
    "    else:\n",
    "        df_expanded['month'] = df_expanded['endTime'].dt.month\n",
    "        genre_diversity = df_expanded.groupby('month')['genres'].nunique()\n",
    "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        genre_diversity.index = genre_diversity.index.map(month_names)\n",
    "    \n",
    "    genre_diversity_growth = genre_diversity.pct_change().fillna(0) * 100\n",
    "\n",
    "    return genre_diversity_growth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genre_popularity_heatmap(genre_popularity, top_n=20):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of genre popularity over time.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    top_n (int): Number of top genres to display in the heatmap. Default is 20.\n",
    "    \"\"\"\n",
    "    # Sum listening time for each genre and select top N genres\n",
    "    top_genres = genre_popularity.sum().nlargest(top_n).index\n",
    "    genre_popularity_top = genre_popularity[top_genres]\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(genre_popularity_top.T, cmap=\"YlGnBu\", cbar_kws={'label': 'Listening Time (minutes)'})\n",
    "    plt.title('Top Genres Popularity Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Genre')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_top_genres_line(genre_popularity, top_n=5):\n",
    "    \"\"\"\n",
    "    Plot a line chart of the top genres over time.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    top_n (int): Number of top genres to display in the line plot. Default is 5.\n",
    "    \"\"\"\n",
    "    top_genres = genre_popularity.sum().nlargest(top_n).index\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for genre in top_genres:\n",
    "        plt.plot(genre_popularity.index, genre_popularity[genre], label=genre)\n",
    "    plt.title(f'Top {top_n} Genres Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Listening Time (minutes)')\n",
    "    plt.legend(title='Genre')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def genre_summary_statistics(genre_popularity):\n",
    "    \"\"\"\n",
    "    Generate summary statistics for genre popularity.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing summary statistics for genre popularity.\n",
    "    \"\"\"\n",
    "    total_listening_time = genre_popularity.sum()\n",
    "    most_popular_genre = total_listening_time.idxmax()\n",
    "    least_popular_genre = total_listening_time.idxmin()\n",
    "\n",
    "    summary = {\n",
    "        \"Most Popular Genre\": most_popular_genre,\n",
    "        \"Total Listening Time of Most Popular Genre (minutes)\": total_listening_time[most_popular_genre],\n",
    "        \"Least Popular Genre\": least_popular_genre,\n",
    "        \"Total Listening Time of Least Popular Genre (minutes)\": total_listening_time[least_popular_genre]\n",
    "    }\n",
    "\n",
    "    print(\"summary statistics for genre popularity generated\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ast\n",
    "\n",
    "def generate_report():\n",
    "    \"\"\"\n",
    "    Function to create a button and text input for generating a PDF report based on user ID.\n",
    "    This version includes the introduction paragraph and PDF generation logic.\n",
    "    \"\"\"\n",
    "    def on_generate_button_click(b):\n",
    "        user_id = user_id_input.value\n",
    "        create_md_report(user_id)\n",
    "        print(f\"Report generated for user ID: {user_id}\")\n",
    "\n",
    "    # Create text input widget for user ID\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    generate_button = widgets.Button(description=\"Generate Report\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    generate_button.on_click(on_generate_button_click)\n",
    "\n",
    "    # Display the input field and button\n",
    "    display(user_id_input, generate_button)\n",
    "\n",
    "\n",
    "\n",
    "def create_md_report(user_id='ezra'):\n",
    "    \"\"\"\n",
    "    Creates a Markdown report for the given user ID with an introduction paragraph and analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    user_id (str): The user ID for which to generate the report.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Set up the Markdown document\n",
    "    file_name = f\"{user_id}_spotify_report.md\"\n",
    "    document_title = \"# Spotify Re-Wrapped 2024\"\n",
    "    intro_text = (\n",
    "        \"Spotify Wrapped for 2024 didn’t quite hit the mark, so I decided to take matters into my own hands. \"\n",
    "        \"This project dives into my actual listening data to get a better picture of my music tastes. \"\n",
    "        \"By analyzing various aspects of my Spotify history, I can uncover patterns, preferences, and trends that \"\n",
    "        \"Spotify's summary might have missed. From listening times and favorite artists to genre distributions, \"\n",
    "        \"this project aims to create a more accurate and personalized Spotify Re-Wrapped experience.\"\n",
    "    )\n",
    "\n",
    "    # Read the user's listening data from a CSV file\n",
    "    file_path = f\"{user_id}_listening_data.csv\"\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "    # Expand and standardize artists involved\n",
    "    df = expand_artists_involved(df)\n",
    "\n",
    "    df_og = df.copy()\n",
    "\n",
    "    ######## Perform analysis  ##########\n",
    "    #general\n",
    "    total_time_hours = total_listening_time_per_user(df)\n",
    "    biggest_date, total_minutes_on_biggest_date = biggest_listening_date(df)\n",
    "    unique_counts = calculate_unique_counts(df)\n",
    "    common_days = common_listening_days(df)\n",
    "    monthly_patterns = monthly_listening_patterns(df)\n",
    "    general_span = general_attention_span(df)\n",
    "    listening_ranges = listening_percentage_categories(df)\n",
    "\n",
    "    \n",
    "    #artist\n",
    "    top_artists_time = top_artists_by_time(df)\n",
    "    top_artists_count = top_artists_by_count(df)\n",
    "    top_artists_weighted_time = top_artists_by_weighted_time(df)\n",
    "    top_artists_weighted_count = top_artists_by_weighted_count(df)\n",
    "    top_weighted_artists_month = top_weighted_artists_per_month(df)\n",
    "    # Identify top collaborating artists\n",
    "   # Identify top collaborating artists\n",
    "    top_collaborating_artists_df = top_collaborating_artists(df, top_n=10)\n",
    "    formatted_top_collaborating_artists = \"\\n\".join([f\"- **{pair[0]} & {pair[1]}**: {count} collaborations\" for pair, count in top_collaborating_artists_df[['artist_pair', 'collaboration_count']].values])\n",
    "\n",
    "    artist_span, artist_listened_time = artist_attention_span(df)\n",
    "\n",
    "    # # Normalize the index of artist_span and top_artists_weighted_time\n",
    "    # artist_span.index = artist_span.index.str.lower()\n",
    "\n",
    "    \n",
    "    songs_by_plays_month = top_songs_by_plays_per_month(df)\n",
    "    weighted_songs_month = top_songs_by_weighted_time_per_month(df)\n",
    "\n",
    "    artist_diversity_growth_result = artist_diversity_growth(df)\n",
    "    # Calculate genre diversity per month and growth\n",
    "    genre_diversity_per_month_result = genre_diversity_per_month(df, distinguish_years=True)\n",
    "    genre_diversity_growth_result = genre_diversity_growth(df, distinguish_years=True)\n",
    "\n",
    "    #genre\n",
    "    # Call the function to get the top genres for the year\n",
    "    top_genres_year = top_genres_for_year(df)\n",
    "\n",
    "    # Check the type of the returned value\n",
    "    top_genres_month = top_genres_per_month(df, distinguish_years=True)\n",
    "    top_genres_year_list = top_genres_year.index.tolist()\n",
    "    top_tracks_by_genres = top_tracks_by_top_genres(df, top_genres_year_list)\n",
    "\n",
    "    # Calculate top songs\n",
    "    top_songs_unweighted_time = top_songs_by_listening_time(df, top_n=10, weighted=False)\n",
    "    top_songs_weighted_time = top_songs_by_listening_time(df, top_n=10, weighted=True)\n",
    "    top_songs_unweighted_totals = top_songs_by_listen_totals(df, top_n=10, weighted=False)\n",
    "    top_songs_weighted_totals = top_songs_by_listen_totals(df, top_n=10, weighted=True)\n",
    "\n",
    "    \n",
    "    ######## Format the messages for Markdown ########\n",
    "    def format_artist_count(artist_counts):\n",
    "        formatted_counts = []\n",
    "        if isinstance(artist_counts, pd.Series):\n",
    "            for artist, count in artist_counts.items():\n",
    "                formatted_counts.append(f\"- **{artist}**: {float(count):.2f} weighted plays\")\n",
    "        elif isinstance(artist_counts, pd.DataFrame):\n",
    "            for index, row in artist_counts.iterrows():\n",
    "                artist = index\n",
    "                count = row.iloc[0]\n",
    "                formatted_counts.append(f\"- **{artist}**: {float(count):.2f} weighted plays\")\n",
    "        return formatted_counts\n",
    "\n",
    "    \n",
    "    def format_artist_time(artist_times):\n",
    "        formatted_times = []\n",
    "        if isinstance(artist_times, pd.Series):\n",
    "            for artist, time in artist_times.items():\n",
    "                minutes = time / (1000 * 60)  # Convert from milliseconds to minutes\n",
    "                hours = time / (1000 * 60 * 60)  # Convert from milliseconds to hours\n",
    "                formatted_times.append(f\"- **{artist}**: {minutes:.2f} min. ({hours:.2f} hr.)\")\n",
    "        elif isinstance(artist_times, pd.DataFrame):\n",
    "            for index, row in artist_times.iterrows():\n",
    "                artist = index\n",
    "                time = row.iloc[0]\n",
    "                minutes = time / (1000 * 60)\n",
    "                hours = time / (1000 * 60 * 60)\n",
    "                formatted_times.append(f\"- **{artist}**: {minutes:.2f} min. ({hours:.2f} hr.)\")\n",
    "        return formatted_times\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    total_listening_time_message = f\"You listened to **{total_time_hours[user_id]:.2f}** hours of music this year.\"\n",
    "    top_day_message = f\"You listened to the most music on **{biggest_date.strftime('%B %d, %Y')}**! A whole **{total_minutes_on_biggest_date:.2f}** minutes of music!\"\n",
    "    unique_counts_msg = f\"You listened to **{unique_counts['unique_songs']} unique songs** this year. That's music from **{unique_counts['unique_artists']} different artists** and on **{unique_counts['unique_albums']} different albums**! Way to go!\"\n",
    "    \n",
    "    formatted_artists_time = \"\\n\".join(format_artist_time(top_artists_time))\n",
    "    formatted_artists_count = \"\\n\".join([f\"- **{artist}**: {count} plays\" for artist, count in top_artists_count.items()])\n",
    "    formatted_artists_time_w = \"\\n\".join(format_artist_time(top_artists_weighted_time))\n",
    "    formatted_artists_count_w = \"\\n\".join(format_artist_count(top_artists_weighted_count))\n",
    "\n",
    "    formatted_genres_year = \"\\n\".join([f\"- **{genre.title()}**\" for genre in top_genres_year.index])\n",
    "    formatted_top_genres_month = \"\\n\".join([f\"**{period}**: \" + \", \".join(genres) for period, genres in top_genres_month.items()])\n",
    "    \n",
    "    formatted_weighted_artists_month = \"\\n\".join([f\"**{month}**: \" + \", \".join(artists) for month, artists in top_weighted_artists_month.items()])\n",
    "    formatted_artist_diversity_growth = \"\\n\".join([f\"**{month}**: {growth:.2f}% growth\" for month, growth in artist_diversity_growth_result.items()])\n",
    "    formatted_common_days = \"\\n\".join([f\"**{day}**: {count} times\" for day, count in common_days.items()])\n",
    "\n",
    "    formatted_songs_by_plays_month = \"\\n\".join([f\"**{month}**: \" + \", \".join(songs) for month, songs in songs_by_plays_month.items()])\n",
    "    formatted_weighted_songs_month = \"\\n\".join([f\"**{month}**: \" + \", \".join(songs) for month, songs in weighted_songs_month.items()])\n",
    "\n",
    "    formatted_monthly_patterns = \"\\n\".join([f\"{month}: {duration:.2f} minutes\" for month, duration in monthly_patterns.items()])\n",
    "\n",
    "    # Formatting top songs\n",
    "    formatted_top_songs_unweighted_time = \"\\n\".join([f\"- **{song}**: {time['listening_time'] / (1000 * 60):.2f} min.\" for song, time in top_songs_unweighted_time.iterrows()])\n",
    "    formatted_top_songs_weighted_time = \"\\n\".join([f\"- **{song}**: {time['listening_time'] / (1000 * 60):.2f} min.\" for song, time in top_songs_weighted_time.iterrows()])\n",
    "    formatted_top_songs_unweighted_totals = \"\\n\".join([f\"- **{song}**: {count['listen_totals']} plays\" for song, count in top_songs_unweighted_totals.iterrows()])\n",
    "    formatted_top_songs_weighted_totals = \"\\n\".join([f\"- **{song}**: {count['listen_totals']:.2f} weighted plays\" for song, count in top_songs_weighted_totals.iterrows()])\n",
    "\n",
    "        \n",
    "    # Filter the artist_span to only include these top artists and handle any missing artists\n",
    "    top_artists = top_artists_weighted_time.index\n",
    "    filtered_artist_span = {artist: artist_span.get(artist, None) for artist in top_artists}\n",
    "\n",
    "    formatted_artist_attention_span = []\n",
    "    for artist, span in filtered_artist_span.items():\n",
    "        if span is not None:\n",
    "            if isinstance(span, pd.Series):\n",
    "                span = span.iloc[0]\n",
    "            formatted_artist_attention_span.append(f\"- **{artist.title()}**: {span:.2f}% average attention span\")\n",
    "        else:\n",
    "            formatted_artist_attention_span.append(f\"- **{artist.title()}**: Data not available\")\n",
    "    formatted_artist_attention_span = \"\\n\".join(formatted_artist_attention_span)\n",
    "\n",
    "    # Formatting genre diversity per month and growth\n",
    "    formatted_genre_diversity_per_month = \"\\n\".join([f\"**{month}**: {diversity} genres\" for month, diversity in genre_diversity_per_month_result.items()])\n",
    "    formatted_genre_diversity_growth = \"\\n\".join([f\"**{month}**: {growth:.2f}% growth\" for month, growth in genre_diversity_growth_result.items()])\n",
    "\n",
    "\n",
    "    general_attention_message = f\"The average percentage of tracks listened to before skipping is **{general_span:.2f}%**.\"\n",
    "\n",
    "    formatted_listening_ranges = \"\\n\".join([f\"**{range_label}**: {count} times\" for range_label, count in listening_ranges.items()])\n",
    "\n",
    "    top_genres_month = top_genres_per_month(df_og, distinguish_years=True)\n",
    "    formatted_top_genres_month = \"\\n\".join([f\"**{period}**: \" + \", \".join(genres) for period, genres in top_genres_month.items()])\n",
    "\n",
    "\n",
    "    ########## Write the Markdown content to file ##########\n",
    "    with open(file_name, 'w', encoding='utf-8') as md_file:\n",
    "        # Introduction\n",
    "        md_file.write(f\"{document_title}\\n\\n{intro_text}\\n\\n\")\n",
    "\n",
    "        # General Section\n",
    "        md_file.write(\"## General Listening Data\\n\")\n",
    "        md_file.write(f\"{total_listening_time_message}\\n\\n{top_day_message}\\n\\n{unique_counts_msg}\\n\\n\")\n",
    "        md_file.write(f\"### Most Common Listening Days\\n{formatted_common_days}\\n\\n\")\n",
    "        md_file.write(f\"### Monthly Listening Patterns\\n{formatted_monthly_patterns}\\n\\n\")\n",
    "        md_file.write(f\"### General Attention Span\\n{general_attention_message}\\n\\n\")\n",
    "        md_file.write(f\"### Listening Percentage Categories\\n{formatted_listening_ranges}\\n\\n\")\n",
    "\n",
    "        # Artists Section\n",
    "        md_file.write(\"## Artist Data\\n\")\n",
    "        md_file.write(f\"### Top Artists by Listening Time\\n{formatted_artists_time}\\n\\n\")\n",
    "        md_file.write(f\"### Top Artists by Weighted Listening Time\\n{formatted_artists_time_w}\\n\\n\")\n",
    "        md_file.write(f\"### Top Artists by Count\\n{formatted_artists_count}\\n\\n\")\n",
    "        md_file.write(f\"### Top Artists by Weighted Count\\n{formatted_artists_count_w}\\n\\n\")\n",
    "        md_file.write(f\"### Top Weighted Artists per Month\\n{formatted_weighted_artists_month}\\n\\n\")\n",
    "        md_file.write(f\"### Artist Diversity Growth\\n{formatted_artist_diversity_growth}\\n\\n\")\n",
    "        md_file.write(f\"### Artist Attention Span\\n{formatted_artist_attention_span}\\n\\n\")\n",
    "        md_file.write(f\"### Top Collaborating Artists\\n{formatted_top_collaborating_artists}\\n\\n\")\n",
    "\n",
    "        # Songs Section\n",
    "        md_file.write(\"## Song Data\\n\")\n",
    "        md_file.write(f\"### Top Songs by Listening Time\\n\")\n",
    "        md_file.write(f\"#### Unweighted Listening Time\\n{formatted_top_songs_unweighted_time}\\n\\n\")\n",
    "        md_file.write(f\"#### Weighted Listening Time\\n{formatted_top_songs_weighted_time}\\n\\n\")\n",
    "        md_file.write(f\"### Top Songs by Listen Totals\\n\")\n",
    "        md_file.write(f\"#### Unweighted Listen Totals\\n{formatted_top_songs_unweighted_totals}\\n\\n\")\n",
    "        md_file.write(f\"#### Weighted Listen Totals\\n{formatted_top_songs_weighted_totals}\\n\\n\")\n",
    "        md_file.write(f\"### Top Songs by Unweighted Plays per Month\\n{formatted_songs_by_plays_month}\\n\\n\")\n",
    "        md_file.write(f\"### Top Songs by Weighted Listening Time per Month\\n{formatted_weighted_songs_month}\\n\\n\")\n",
    "\n",
    "        # Genres Section\n",
    "        md_file.write(\"## Genre Data\\n\")\n",
    "        md_file.write(f\"### Top Genres for the Year\\n{formatted_genres_year}\\n\\n\")\n",
    "        md_file.write(f\"### Top Genres Per Month\\n{formatted_top_genres_month}\\n\\n\")\n",
    "        md_file.write(f\"### Top Tracks by Top Genres\\n{top_tracks_by_genres}\\n\\n\")\n",
    "\n",
    "        # Genre Diversity Section\n",
    "        md_file.write(\"## Genre Diversity Data\\n\")\n",
    "        md_file.write(f\"### Genre Diversity Per Month\\n{formatted_genre_diversity_per_month}\\n\\n\")\n",
    "        md_file.write(f\"### Genre Diversity Growth\\n{formatted_genre_diversity_growth}\\n\\n\")\n",
    "\n",
    "        \n",
    "    print(f\"Markdown report created: {file_name}\")\n",
    "\n",
    "# Call the function to generate the Markdown report\n",
    "#create_md_report(user_id=\"ezra\")\n",
    "\n",
    "generate_report()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Frame, PageBreak\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from reportlab.platypus import Paragraph, Image, SimpleDocTemplate, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import os\n",
    "from reportlab.pdfbase.ttfonts import TTFont \n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "\n",
    "\n",
    "\n",
    "def generate_report():\n",
    "    \"\"\"\n",
    "    Function to create a button and text input for generating a PDF report based on user ID.\n",
    "    This version includes the introduction paragraph and PDF generation logic.\n",
    "    \"\"\"\n",
    "    def on_generate_button_click(b):\n",
    "        user_id = user_id_input.value\n",
    "        create_pdf_report(user_id)\n",
    "        print(f\"Report generated for user ID: {user_id}\")\n",
    "\n",
    "    # Create text input widget for user ID\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    generate_button = widgets.Button(description=\"Generate Report\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    generate_button.on_click(on_generate_button_click)\n",
    "\n",
    "    # Display the input field and button\n",
    "    display(user_id_input, generate_button)\n",
    "\n",
    "def create_pdf_report(user_id='ezra'):\n",
    "    \"\"\"\n",
    "    Creates a PDF report for the given user ID with an introduction paragraph and analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    user_id (str): The user ID for which to generate the report.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def save_partial_pdf(doc, elements, part):\n",
    "        doc.build(elements)\n",
    "        elements.clear()\n",
    "        elements.append(PageBreak())\n",
    "        print(f\"Part {part} of the PDF saved.\")\n",
    "\n",
    "    # Set up the PDF document\n",
    "    file_name = f\"{user_id}_spotify_report.pdf\"\n",
    "    document_title = \"Spotify Re-Wrapped 2024\"\n",
    "    intro_text = (\n",
    "        \"Spotify Wrapped for 2024 didn’t quite hit the mark, so I decided to take matters into my own hands. \"\n",
    "        \"This project dives into my actual listening data to get a better picture of my music tastes. \"\n",
    "        \"By analyzing various aspects of my Spotify history, I can uncover patterns, preferences, and trends that \"\n",
    "        \"Spotify's summary might have missed. From listening times and favorite artists to genre distributions, \"\n",
    "        \"this project aims to create a more accurate and personalized Spotify Re-Wrapped experience.\"\n",
    "    )\n",
    "\n",
    "    # Read the user's listening data from a CSV file\n",
    "    file_path = f\"{user_id}_listening_data.csv\"\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "    # Expand and standardize artists involved\n",
    "    df = expand_artists_involved(df)\n",
    "\n",
    "    ######## Perform analysis  ##########\n",
    "    #general\n",
    "    total_time_hours = total_listening_time_per_user(df)\n",
    "    biggest_date, total_minutes_on_biggest_date = biggest_listening_date(df)\n",
    "    unique_counts = calculate_unique_counts(df)\n",
    "    common_days = common_listening_days(df)\n",
    "    monthly_patterns = monthly_listening_patterns(df)\n",
    "    general_span = general_attention_span(df)\n",
    "    listening_ranges = listening_percentage_categories(df)\n",
    "\n",
    "    \n",
    "    #artist\n",
    "    top_artists_time = top_artists_by_time(df)\n",
    "    top_artists_count = top_artists_by_count(df)\n",
    "    top_artists_weighted_time = top_artists_by_weighted_time(df)\n",
    "    top_artists_weighted_count = top_artists_by_weighted_count(df)\n",
    "    top_weighted_artists_month = top_weighted_artists_per_month(df)\n",
    "    artist_span, artist_listened_time = artist_attention_span(df)\n",
    "\n",
    "    # Normalize the index of artist_span and top_artists_weighted_time\n",
    "    artist_span.index = artist_span.index.str.lower()\n",
    "    top_artists_weighted_time.index = top_artists_weighted_time.index.str.lower()\n",
    "\n",
    "    \n",
    "    songs_by_plays_month = top_songs_by_plays_per_month(df)\n",
    "    weighted_songs_month = top_songs_by_weighted_time_per_month(df)\n",
    "\n",
    "\n",
    "    artist_diversity_growth_result = artist_diversity_growth(df)\n",
    "    \n",
    "\n",
    "    #genre\n",
    "    top_genres_year = top_genres_for_year(df)\n",
    "    # top_genres_month = top_genres_per_month(df, distinguish_years=True)\n",
    "\n",
    "\n",
    "    ######## Create the PDF document using SimpleDocTemplate\n",
    "    doc = SimpleDocTemplate(file_name, pagesize=letter)\n",
    "    \n",
    "    # Define styles for the document\n",
    "    styles = getSampleStyleSheet()\n",
    "    header_style = ParagraphStyle(name='Header', fontName='Helvetica-Bold', fontSize=18, leading=22)\n",
    "    body_style = ParagraphStyle(name='Body', fontName='Helvetica', fontSize=12, leading=14)\n",
    "    # Create the header and introduction paragraph\n",
    "    header = Paragraph(document_title, header_style)\n",
    "    introduction = Paragraph(intro_text, body_style)\n",
    "\n",
    "    ########### Format the message \n",
    "    total_listening_time_message = f\"You listened to <b>{total_time_hours[user_id]:.2f}</b> hours of music this year.\"\n",
    "    top_day_message = f\"You listened to the most music on <b>{biggest_date.strftime('%B %d, %Y')}</b>! A whole <b>{total_minutes_on_biggest_date:.2f}</b> minutes of music!\"\n",
    "    unique_counts_msg = f\"You listened to <b>{unique_counts['unique_songs']} unique songs</b> this year. That's music from <b>{unique_counts['unique_artists']} different artists</b> and on <b>{unique_counts['unique_albums']} different albums</b>! Way to go!\"\n",
    "    \n",
    "    formatted_artists_time = [] \n",
    "    for artist, time in top_artists_time.items(): \n",
    "        minutes = time / 60 \n",
    "        hours = time / 3600 \n",
    "        formatted_artists_time.append(f\"{artist.title()} - {minutes:.2f} min. ({hours:.2f} hr.)\")\n",
    "    formatted_artists_time = \"<br/>\".join(formatted_artists_time)\n",
    "\n",
    "    formatted_artists_count = [] \n",
    "    for artist, count in top_artists_count.items(): \n",
    "        formatted_artists_count.append(f\"{artist.title()} - {count} plays.\")\n",
    "    formatted_artists_count = \"<br/>\".join(formatted_artists_count)\n",
    "\n",
    "\n",
    "    formatted_artists_time_w = []\n",
    "    if isinstance(top_artists_weighted_time, pd.DataFrame):\n",
    "        for index, row in top_artists_weighted_time.iterrows():\n",
    "            artist = index\n",
    "            time = row['weighted_time']\n",
    "            minutes = time / (1000 * 60)  # Convert from milliseconds to minutes\n",
    "            hours = time / (1000 * 60 * 60)  # Convert from milliseconds to hours\n",
    "            formatted_artists_time_w.append(f\"{artist.title()} - {minutes:.2f} weighted min. ({hours:.2f} weighted hr.)\")\n",
    "    else:\n",
    "        for artist, time in top_artists_weighted_time.items():\n",
    "            minutes = time / (1000 * 60)  # Convert from milliseconds to minutes\n",
    "            hours = time / (1000 * 60 * 60)  # Convert from milliseconds to hours\n",
    "            formatted_artists_time_w.append(f\"{artist.title()} - {minutes:.2f} weighted min. ({hours:.2f} weighted hr.)\")\n",
    "    formatted_artists_time_w = \"<br/>\".join(formatted_artists_time_w)\n",
    "\n",
    "    formatted_artists_count_w = []\n",
    "    if isinstance(top_artists_weighted_count, pd.DataFrame):\n",
    "        for index, row in top_artists_weighted_count.iterrows():\n",
    "            artist = index\n",
    "            count = row['weighted_listens']\n",
    "            formatted_artists_count_w.append(f\"{artist.title()} - {count:.2f} weighted plays\")\n",
    "    else:\n",
    "        for artist, count in top_artists_weighted_count.items():\n",
    "            formatted_artists_count_w.append(f\"{artist.title()} - {count:.2f} weighted plays\")\n",
    "    formatted_artists_count_w = \"<br/>\".join(formatted_artists_count_w)\n",
    "\n",
    "\n",
    "    formatted_genres_year = []\n",
    "    for genre in top_genres_year:\n",
    "        formatted_genres_year.append(f\"- {genre.title()}\")\n",
    "    formatted_genres_year = \"<br/>\".join(formatted_genres_year)\n",
    "\n",
    "    # Initialize a list to store formatted tracks by genre\n",
    "    formatted_genre_tracks = []\n",
    "\n",
    "    # Loop through the top 5 genres and get the top tracks for each\n",
    "    for genre in top_genres_year[:5]:\n",
    "        top_tracks_genre = top_tracks_by_genre(df, genre)\n",
    "        \n",
    "        formatted_tracks = []\n",
    "        for track, minutes in top_tracks_genre:\n",
    "            formatted_tracks.append(f\"{track} - {minutes:.2f} min.\")\n",
    "        formatted_tracks = \"<br/>\".join(formatted_tracks)\n",
    "        formatted_genre_tracks.append(f\"<b>Top Tracks in {genre.title()}:</b><br/>{formatted_tracks}\")\n",
    "\n",
    "    # Combine all the formatted tracks by genre into a single string\n",
    "    formatted_genre_tracks = \"<br/><br/>\".join(formatted_genre_tracks)\n",
    "\n",
    "    formatted_weighted_artists_month = []\n",
    "    for month, artists in top_weighted_artists_month.items():\n",
    "        formatted_weighted_artists_month.append(f\"<b>{month}:</b> \" + \", \".join(artists))\n",
    "    formatted_weighted_artists_month = \"<br/>\".join(formatted_weighted_artists_month)\n",
    "\n",
    "    formatted_artist_diversity_growth = []\n",
    "    for month, growth in artist_diversity_growth_result.items():\n",
    "        formatted_artist_diversity_growth.append(f\"<b>{month}:</b> {growth:.2f}% growth\")\n",
    "    formatted_artist_diversity_growth = \"<br/>\".join(formatted_artist_diversity_growth)\n",
    "\n",
    "    formatted_common_days = []\n",
    "    for day, count in common_days.items():\n",
    "        formatted_common_days.append(f\"{day}: {count} times\")\n",
    "    formatted_common_days = \"<br/>\".join(formatted_common_days)\n",
    "\n",
    "\n",
    "    formatted_songs_by_plays_month = []\n",
    "    for month, songs in songs_by_plays_month.items():\n",
    "        formatted_songs_by_plays_month.append(f\"<b>{month}:</b> \" + \", \".join(songs))\n",
    "    formatted_songs_by_plays_month = \"<br/>\".join(formatted_songs_by_plays_month)\n",
    "    formatted_weighted_songs_month = []\n",
    "    for month, songs in weighted_songs_month.items():\n",
    "        formatted_weighted_songs_month.append(f\"<b>{month}:</b> \" + \", \".join(songs))\n",
    "    formatted_weighted_songs_month = \"<br/>\".join(formatted_weighted_songs_month)\n",
    "\n",
    "\n",
    "    formatted_monthly_patterns = []\n",
    "    for month, duration in monthly_patterns.items():\n",
    "        formatted_monthly_patterns.append(f\"{month}: {duration:.2f} minutes\")\n",
    "    formatted_monthly_patterns = \"<br/>\".join(formatted_monthly_patterns)\n",
    "\n",
    "    # Get the list of top artists by weighted listening time\n",
    "    top_artists = top_artists_weighted_time.index\n",
    "\n",
    "    # Filter the artist_span to only include these top artists and handle any missing artists\n",
    "    filtered_artist_span = {artist: artist_span.get(artist, None) for artist in top_artists}\n",
    "\n",
    "    # Format the results\n",
    "    formatted_artist_attention_span = []\n",
    "    formatted_artist_attention_span.append(\"<b>Attention Span for Top Artists by Weighted Listening Time:</b>\")\n",
    "    for artist, span in filtered_artist_span.items():\n",
    "        if span is not None:\n",
    "            if isinstance(span, pd.Series):\n",
    "                span = span.iloc[0]\n",
    "            formatted_artist_attention_span.append(f\"{artist.title()}: {span:.2f}% average attention span\")\n",
    "        else:\n",
    "            formatted_artist_attention_span.append(f\"{artist.title()}: Data not available\")\n",
    "    formatted_artist_attention_span = \"<br/>\".join(formatted_artist_attention_span)\n",
    "\n",
    "\n",
    "    general_attention_message = f\"The average percentage of tracks listened to before skipping is <b>{general_span:.2f}%</b>.\"\n",
    "\n",
    "    formatted_listening_ranges = []\n",
    "    for range_label, count in listening_ranges.items():\n",
    "        formatted_listening_ranges.append(f\"{range_label}: {count} times\")\n",
    "    formatted_listening_ranges_message = \"<br/>\".join(formatted_listening_ranges)\n",
    "\n",
    "    # formatted_top_genres_month = []\n",
    "    # for period, genres in top_genres_month.items():\n",
    "    #     formatted_top_genres_month.append(f\"<b>{period}:</b> \" + \", \".join(genres))\n",
    "    # formatted_top_genres_month = \"<br/>\".join(formatted_top_genres_month)\n",
    "\n",
    "    \n",
    "\n",
    "    ########## Assemble the elements\n",
    "    elements = [header, introduction, Spacer(1, 12)]\n",
    "    part = 1\n",
    "\n",
    "    ######### Add analysis results to the PDF in sections\n",
    "    analysis_results = [\n",
    "        #general\n",
    "        (\"<b>Total Listening Time per User (in hours):</b>\", total_listening_time_message),\n",
    "        (\"<b>Biggest Listening Date and Total Minutes Listened:</b>\", top_day_message),\n",
    "        (\"<b>Number of Unique Songs, Artists, and Albums:</b>\", unique_counts_msg),\n",
    "        (\"<b>Most Common Listening Days:</b>\", formatted_common_days),\n",
    "        (\"<b>Monthly Listening Patterns:</b>\", formatted_monthly_patterns),\n",
    "        (\"<b>General Attention Span:</b>\", general_attention_message),\n",
    "        (\"<b>Listening Percentage Categories:</b>\", formatted_listening_ranges_message),\n",
    "\n",
    "        \n",
    "        #artists\n",
    "        (\"<b>Top Artists by Listening Time:</b>\", formatted_artists_time),\n",
    "        (\"<b>Top Artists by Count:</b>\", formatted_artists_count),\n",
    "        (\"<b>Top Artists by Weighted Listening Time:</b>\", formatted_artists_time_w),\n",
    "        (\"<b>Top Artists by Weighted Count:</b>\", formatted_artists_count_w),\n",
    "        (\"<b>Top Weighted Artists per Month:</b>\", formatted_weighted_artists_month),\n",
    "        (\"<b>Artist Diversity Growth:</b>\", formatted_artist_diversity_growth),\n",
    "        (\"<b>Artist Attention Span:</b>\", formatted_artist_attention_span),\n",
    "\n",
    "\n",
    "        (\"<b>Top Songs by Unweighted Plays per Month:</b>\", formatted_songs_by_plays_month),\n",
    "        (\"<b>Top Songs by Weighted Listening Time per Month:</b>\", formatted_weighted_songs_month),\n",
    "\n",
    "\n",
    "        (\"<b>Top Genres for the Year:</b>\", formatted_genres_year),\n",
    "        #(\"<b>Top Genres Per Month:</b>\", formatted_top_genres_month),\n",
    "        (\"<b>Top Tracks by Genre:</b>\", formatted_genre_tracks),\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "    for idx, (title, content) in enumerate(analysis_results):\n",
    "        elements.append(Paragraph(\"<br/>\" + title, body_style))\n",
    "        elements.append(Paragraph(content, body_style))\n",
    "        \n",
    "    save_partial_pdf(doc, elements, part)\n",
    "\n",
    "\n",
    "\n",
    "def get_unique_genres(df):\n",
    "    \"\"\"\n",
    "    Get unique genres from the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the listening data.\n",
    "\n",
    "    Returns:\n",
    "        set: Set containing unique genres.\n",
    "    \"\"\"\n",
    "    unique_genres = set()\n",
    "    for genres_list in df['genres']:\n",
    "        for genre in genres_list:\n",
    "            unique_genres.add(genre)\n",
    "    return unique_genres\n",
    "\n",
    "\n",
    "# Call the function to display the input fields and button for generating a report\n",
    "generate_report()\n",
    "\n",
    "#create_pdf_report(user_id=\"ezra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Paragraph, Image, SimpleDocTemplate, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import os\n",
    "\n",
    "def ensure_album_art(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Ensure album art for a given artist exists, either by checking locally or fetching from Spotify API.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check and save album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    sanitized_artist_name = artist_name.replace(' ', '_').lower()\n",
    "    if not check_album_art_exists(sanitized_artist_name, folder):\n",
    "        token = get_spotify_token()\n",
    "        fetch_album_art(artist_name, token, folder)\n",
    "\n",
    "def check_album_art_exists(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Check if the album art for a given artist exists in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check for album art. Defaults to 'albums'.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if album art exists, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = f\"{folder}/{artist_name}.jpg\"\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def generate_artist_elements_with_images(top_artists_time):\n",
    "    \"\"\"\n",
    "    Generate a list of reportlab Flowable elements with album art and listening time for each artist.\n",
    "\n",
    "    Parameters:\n",
    "    top_artists_time (pandas.Series): A Series where the index contains artist names and the values contain the listening times.\n",
    "\n",
    "    Returns:\n",
    "    list: List of Flowable elements with album art and listening times for each artist.\n",
    "    \"\"\"\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    style = styles['Normal']\n",
    "    \n",
    "    for artist, time in top_artists_time.items():\n",
    "        sanitized_artist_name = artist.replace(' ', '_').lower()\n",
    "        ensure_album_art(artist)\n",
    "        album_art_path = f\"albums/{sanitized_artist_name}.jpg\"\n",
    "        if os.path.isfile(album_art_path):\n",
    "            img = Image(album_art_path, width=50, height=50)\n",
    "        else:\n",
    "            img = Image('placeholder.jpg', width=50, height=50)\n",
    "        \n",
    "        artist_text = f\"{artist}: {time:.2f} seconds\"\n",
    "        elements.append(img)\n",
    "        elements.append(Paragraph(artist_text, style))\n",
    "        elements.append(Spacer(1, 12))  # Add some space between entries\n",
    "    \n",
    "    return elements\n",
    "\n",
    "# Assuming 'df' is your DataFrame with Spotify listening data\n",
    "top_artists_time = top_artists_by_time(df)\n",
    "artist_elements = generate_artist_elements_with_images(top_artists_time)\n",
    "\n",
    "# Example usage in a SimpleDocTemplate\n",
    "doc = SimpleDocTemplate(\"example_report.pdf\", pagesize=letter)\n",
    "doc.build(artist_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Main Functions</h1></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Process and Track Songs:</strong> Function to process raw listening data, add songs to the unique_songs file, and save the new CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def process_and_track_songs(base_path='../wrapped_files/', unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Process the raw listening data, track unique songs, and save to CSV.\n",
    "\n",
    "    This function processes the raw listening data by reading and combining multiple chunks,\n",
    "    adds all unique songs into the unique_songs file, and saves the processed data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    base_path (str, optional): The base path to the directory containing the raw listening data files. \n",
    "                               Defaults to '../wrapped_files/'.\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_process_button_click(b):\n",
    "        user_id = user_id_input.value\n",
    "        num_chunks = num_chunks_input.value\n",
    "\n",
    "        try:\n",
    "            df = read_and_process_data(user_id, num_chunks, base_path)\n",
    "            export_to_csv(df, user_id)\n",
    "            track_unique_songs(df, unique_songs_file)\n",
    "\n",
    "            print(\"Data processing complete!\")\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "    # Create text input widgets for user ID and number of chunks\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "    num_chunks_input = widgets.IntText(description=\"Num Chunks:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    process_button = widgets.Button(description=\"Process and Export Data\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    process_button.on_click(on_process_button_click)\n",
    "\n",
    "    # Display the input fields and button\n",
    "    display(user_id_input, num_chunks_input, process_button)\n",
    "\n",
    "# Call the function to display the widgets and set up the processing\n",
    "process_and_track_songs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_unique_songs_data(unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Update the unique songs table with Spotify info.\n",
    "\n",
    "    This function updates the unique songs table with information from Spotify.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_update_button_click(b):\n",
    "        update_unique_songs(unique_songs_file)\n",
    "        print(\"Unique songs table updated with Spotify info.\")\n",
    "\n",
    "    # Create a button widget for updating unique songs\n",
    "    update_button = widgets.Button(description=\"Update Unique Songs\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    update_button.on_click(on_update_button_click)\n",
    "\n",
    "    # Display the button\n",
    "    display(update_button)\n",
    "\n",
    "# Call the function to set up the button for updating unique songs\n",
    "update_unique_songs_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the unique songs database\n",
    "unique_songs_file = 'unique_songs.csv'\n",
    "unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "# Sort the database by artistName\n",
    "sorted_unique_songs = unique_songs.sort_values(by='artistName')\n",
    "\n",
    "# Save the sorted database to a new CSV file\n",
    "sorted_unique_songs_file = 'sorted_unique_songs.csv'\n",
    "sorted_unique_songs.to_csv(sorted_unique_songs_file, index=False)\n",
    "\n",
    "print(f\"Sorted unique songs database saved to {sorted_unique_songs_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "def process_filled_listening_data(unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Load unique songs data, get user ID, read processed listening data,\n",
    "    fill in song info, calculate percentage listened, remove empty genre column,\n",
    "    and export to CSV.\n",
    "\n",
    "    This function loads unique songs data, gets the user ID, reads the processed listening data,\n",
    "    fills in song info from the unique songs database, calculates the percentage listened for each track,\n",
    "    checks and removes the empty 'genre' column, and exports the filled data to a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_process_button_click(b):\n",
    "        unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "        user_id = user_id_input.value\n",
    "        try:\n",
    "            listening_data = read_processed_data(user_id)\n",
    "            \n",
    "            filled_listening_data = fill_song_info(listening_data, unique_songs)\n",
    "\n",
    "            # Check if 'duration_ms' column is present\n",
    "            if 'duration_ms' not in filled_listening_data.columns:\n",
    "                print(\"Warning: 'duration_ms' column is missing in filled_listening_data.\")\n",
    "                return\n",
    "            \n",
    "            # Calculate percentage listened\n",
    "            filled_listening_data['percentage_listened'] = (filled_listening_data['msPlayed'] / filled_listening_data['duration_ms']) * 100\n",
    "            \n",
    "            # Check and remove the empty 'genre' column if it exists and is empty\n",
    "            if 'genre' in filled_listening_data.columns and filled_listening_data['genre'].isnull().all():\n",
    "                filled_listening_data = filled_listening_data.drop(columns=['genre'])\n",
    "            \n",
    "            export_filled_data(filled_listening_data, user_id)\n",
    "\n",
    "            print(\"Data processing complete!\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Processed data file not found for user ID: {user_id}\")\n",
    "\n",
    "    # Create text input widgets for user ID\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    process_button = widgets.Button(description=\"Process Filled Listening Data\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    process_button.on_click(on_process_button_click)\n",
    "\n",
    "    # Display the input fields and button\n",
    "    display(user_id_input, process_button)\n",
    "\n",
    "# Call the function to display the input fields and button for processing filled listening data\n",
    "process_filled_listening_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Color Generation Functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a random color\n",
    "def generate_random_color():\n",
    "    color = (random.randint(100, 255), random.randint(100, 255), random.randint(100, 255))\n",
    "    print(f\"Generated random color: {color}\")\n",
    "    return color\n",
    "\n",
    "# Function to generate a color close to a given color\n",
    "def generate_similar_color(color, variance=50):\n",
    "    r = min(max(color[0] + random.randint(-variance, variance), 0), 255)\n",
    "    g = min(max(color[1] + random.randint(-variance, variance), 0), 255)\n",
    "    b = min(max(color[2] + random.randint(-variance, variance), 0), 255)\n",
    "    similar_color = (r, g, b)\n",
    "    print(f\"Generated color similar to {color}: {similar_color}\")\n",
    "    return similar_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Abstract Background Generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an abstract background with dynamic colors\n",
    "def generate_abstract_background(width=1080, height=1920):\n",
    "    print(f\"Generating abstract background of size {width}x{height}\")\n",
    "    start_color = generate_random_color()\n",
    "    end_color = generate_similar_color(start_color)\n",
    "    \n",
    "    # Create a gradient based on the generated colors\n",
    "    gradient = np.linspace(start_color, end_color, width).astype(int)\n",
    "    gradient_cmap = plt.cm.colors.ListedColormap(gradient / 255.0)\n",
    "\n",
    "    x = np.linspace(-5, 5, width)\n",
    "    y = np.linspace(-5, 5, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    Z = np.sin(X**2 + Y**2) * np.cos(Y**2 - X**2)\n",
    "    \n",
    "    plt.figure(figsize=(width / 100, height / 100), dpi=100)\n",
    "    plt.imshow(Z, cmap=gradient_cmap, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('abstract_background.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    background = Image.open('abstract_background.png')\n",
    "    background = background.resize((width, height))\n",
    "    print(\"Abstract background generated and saved as 'abstract_background.png'\")\n",
    "    return background\n",
    "\n",
    "# Function to generate Perlin noise\n",
    "def generate_perlin_noise(width, height, scale=100, seed=random.randint(0,500)):\n",
    "    print(f\"Generating Perlin noise of size {width}x{height} with scale {scale} and seed {seed}\")\n",
    "    shape = (width, height)\n",
    "    world = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            world[i][j] = noise.pnoise2(i / scale, j / scale, octaves=6, persistence=0.5, lacunarity=2.0, repeatx=1024, repeaty=1024, base=seed)\n",
    "    \n",
    "    norm_world = (world - np.min(world)) / (np.max(world) - np.min(world))\n",
    "    print(\"Perlin noise generated\")\n",
    "    return norm_world\n",
    "\n",
    "# Function to generate an abstract background with Perlin noise\n",
    "def generate_abstract_background_with_noise(width=1080, height=1920):\n",
    "    print(f\"Generating abstract background with Perlin noise of size {width}x{height}\")\n",
    "    noise_pattern = generate_perlin_noise(width, height)\n",
    "    \n",
    "    start_color = generate_random_color()\n",
    "    end_color = generate_similar_color(start_color)\n",
    "    gradient = np.linspace(start_color, end_color, width).astype(int)\n",
    "    gradient_cmap = plt.cm.colors.ListedColormap(gradient / 255.0)\n",
    "\n",
    "    plt.figure(figsize=(width / 100, height / 100), dpi=100)\n",
    "    plt.imshow(noise_pattern, cmap=gradient_cmap, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('abstract_background_with_noise.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    background = Image.open('abstract_background_with_noise.png')\n",
    "    background = background.resize((width, height))\n",
    "    print(\"Abstract background with Perlin noise generated and saved as 'abstract_background_with_noise.png'\")\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Text Drawing Function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw wrapped text\n",
    "def draw_wrapped_text(draw, text, position, font, max_width, fill):\n",
    "    print(f\"Drawing wrapped text: {text}\")\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    while words:\n",
    "        line = ''\n",
    "        while words and font.getbbox(line + words[0])[2] <= max_width:\n",
    "            line += (words.pop(0) + ' ')\n",
    "        lines.append(line)\n",
    "    y_offset = position[1]\n",
    "    for line in lines:\n",
    "        draw.text((position[0], y_offset), line, font=font, fill=fill)\n",
    "        y_offset += font.getbbox(line)[3]  # Use getbbox for line height\n",
    "    print(f\"Wrapped text drawn at position {position}\")\n",
    "    return y_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Album Art Download!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch and download all popular album art for each artist\n",
    "def download_all_album_art(df, top_artists):\n",
    "    print(\"Downloading album art for top artists\")\n",
    "    album_art = {}\n",
    "    for artist in top_artists:\n",
    "        artist_data = df[df['artistName'] == artist]\n",
    "        if artist_data.empty:\n",
    "            continue\n",
    "        \n",
    "        art_urls = artist_data['album_artwork'].value_counts().index.tolist()\n",
    "        downloaded = False\n",
    "        for art_url in art_urls:\n",
    "            try:\n",
    "                response = requests.get(art_url)\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                \n",
    "                img_path = os.path.join(\"albums\", f'{artist}_album_art.jpg')\n",
    "                img.save(img_path)\n",
    "                \n",
    "                album_art[artist] = img_path\n",
    "                downloaded = True\n",
    "                print(f\"Downloaded album art for {artist}: {img_path}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {art_url} for {artist}: {e}\")\n",
    "                continue\n",
    "        if not downloaded:\n",
    "            print(f\"Could not download album art for {artist}\")\n",
    "    return album_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Function to create and save layout images\n",
    "def create_layout_image(title, top_artists, album_art, file_name, user_id, background):\n",
    "    print(f\"Creating layout image: {file_name}\")\n",
    "    width, height = background.size\n",
    "    image = background.copy()\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Define fonts\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "        title_font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        user_id_font = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "    except IOError:\n",
    "        # In case the fonts are not available on the system\n",
    "        font = ImageFont.load_default()\n",
    "        title_font = ImageFont.load_default()\n",
    "        user_id_font = ImageFont.load_default()\n",
    "    \n",
    "    # Draw title and user ID\n",
    "    draw.text((width / 2, 50), title, font=title_font, fill=\"white\", anchor=\"mm\")\n",
    "    draw.text((width / 2, 150), f\"User: {user_id}\", font=user_id_font, fill=\"white\", anchor=\"mm\")\n",
    "\n",
    "    y_offset = 250\n",
    "    x_offset = 50\n",
    "\n",
    "    for rank, (artist, value) in enumerate(top_artists.items(), start=1):\n",
    "        if artist not in album_art:\n",
    "            continue\n",
    "        \n",
    "        art = Image.open(album_art[artist]).resize((100, 100))\n",
    "        image.paste(art, (x_offset, y_offset))\n",
    "        \n",
    "        text = f\"{rank}. {artist}: {value}\"\n",
    "        draw.text((x_offset + 120, y_offset + 30), text, font=font, fill=\"white\")\n",
    "        y_offset += 120\n",
    "\n",
    "    image.save(file_name)\n",
    "    print(f\"Layout image saved as {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_filled_listening_data('ezra_listening_data_with_percentage.csv')\n",
    "\n",
    "# Calculate total listening time per user\n",
    "total_time = total_listening_time_per_user(df)\n",
    "print(\"Total listening time per user (in hours):\")\n",
    "print(total_time, \"\\n\")\n",
    "\n",
    "# Identify the biggest listening date\n",
    "biggest_date = biggest_listening_date(df)\n",
    "print(\"Biggest listening date:\")\n",
    "print(biggest_date, \"\\n\")\n",
    "\n",
    "# Analyze top 5 music tastes per month\n",
    "taste_per_month = music_taste_per_month(df)\n",
    "print(\"Top 5 artists per month:\")\n",
    "for month, artists in taste_per_month.items():\n",
    "    print(f\"Month {month}: {artists}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Determine the most common listening days and times\n",
    "common_days = common_listening_days_and_times(df)\n",
    "print(\"Most common listening days:\")\n",
    "print(common_days, \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Album Analysis Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Generate Instagram story-sized abstract background with Perlin noise and custom colormap\n",
    "    background = generate_abstract_background_with_noise(1080, 1920)\n",
    "\n",
    "    # Load unique songs data\n",
    "    unique_songs_file = 'unique_songs.csv'\n",
    "    unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "    # Get user ID and construct the file path\n",
    "    user_name = get_user_id()\n",
    "    file_path = f'{user_name}_listening_data.csv'\n",
    "\n",
    "    try:\n",
    "        # Read the filled listening data\n",
    "        filled_listening_data = read_filled_listening_data(file_path)\n",
    "        \n",
    "        # Calculate percentage listened for each track\n",
    "        filled_listening_data = calculate_percentage_listened(filled_listening_data)\n",
    "        \n",
    "        # Calculate top listened-to artists\n",
    "        top_artists_count = top_artists_by_count(filled_listening_data).head(5)\n",
    "        top_artists_time = top_artists_by_time(filled_listening_data).head(5)\n",
    "        top_artists_weighted_time = top_artists_by_weighted_time(filled_listening_data).head(5)\n",
    "        \n",
    "        # Combine all top artists to ensure all album art is downloaded\n",
    "        all_top_artists = top_artists_count.index.union(top_artists_time.index).union(top_artists_weighted_time.index)\n",
    "        \n",
    "        # Download the most common album art for each artist\n",
    "        album_art = download_all_album_art(filled_listening_data, all_top_artists)\n",
    "        \n",
    "        # Create layout images with user ID in the file name and abstract background\n",
    "        create_layout_image(\"Top Artists by Count\", top_artists_count, album_art, f\"{user_name}_spotify_wrapped_top_artists_count.png\", user_name, background)\n",
    "        create_layout_image(\"Top Artists by Listening Time (minutes)\", {k: v / 60 for k, v in top_artists_time.items()}, album_art, f\"{user_name}_spotify_wrapped_top_artists_time.png\", user_name, background)\n",
    "        create_layout_image(\"Top Artists by Weighted Listening Time\", top_artists_weighted_time, album_art, f\"{user_name}_spotify_wrapped_top_artists_weighted_time.png\", user_name, background)\n",
    "        \n",
    "        print(\"Data processing and layout creation complete!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
