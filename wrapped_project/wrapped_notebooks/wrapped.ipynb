{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Environmental Setup</h1></strong>\n",
    "\n",
    "<strong>Install Required Packages:</strong> Install necessary packages using pip.\n",
    "\n",
    "<strong>Load Environment Variables:</strong> Load environment variables for Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r C:\\Users\\ezrag\\OneDrive\\Documents\\GitHub\\spotify-listening-data\\requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "SPOTIFY_CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "SPOTIFY_CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import queue\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Utility Functions and Initialization</h1></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>User Input Functions</h3>\n",
    "<strong>Get User ID:</strong> Function to get user ID from input.\n",
    "\n",
    "<strong>Get Number of Data Chunks:</strong> Function to get the number of data chunks from input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id():\n",
    "    \"\"\"\n",
    "    Prompt the user to enter their ID and return it in lowercase.\n",
    "\n",
    "    This function prompts the user to enter their ID, converts it to lowercase,\n",
    "    and returns the result.\n",
    "\n",
    "    Returns:\n",
    "    str: The user's ID in lowercase.\n",
    "    \"\"\"\n",
    "    user_id = input(\"Enter the user's ID: \").lower()\n",
    "    return user_id\n",
    "\n",
    "def get_num_chunks():\n",
    "    \"\"\"\n",
    "    Prompt the user to enter the number of data chunks.\n",
    "\n",
    "    This function prompts the user to enter the number of data chunks,\n",
    "    converts the input to an integer, and returns the result.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of data chunks entered by the user.\n",
    "    \"\"\"\n",
    "    num_chunks = int(input(\"Enter the number of chunks: \"))\n",
    "    return num_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Reading and Processing</h3>\n",
    "<strong>Read and Process Data:</strong> Function to read and process data from multiple JSON files.\n",
    "\n",
    "<strong>Export Data to CSV:</strong> Function to export processed data to a CSV file.\n",
    "\n",
    "<strong>Track Unique Songs:</strong> Function to track unique songs and update unique songs list.\n",
    "\n",
    "<strong>Safe Literal Eval:</strong> Function to safely evaluate literals from strings.\n",
    "\n",
    "<strong>Expand Artists Involved:</strong> Function to expand artists involved in each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_data(user_id, num_chunks, base_path='wrapped_files/'):\n",
    "    \"\"\"\n",
    "    Read and process data from multiple JSON files.\n",
    "\n",
    "    This function reads data from multiple JSON files specified by the user ID\n",
    "    and number of chunks, processes the data, and returns it as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (str): The user's ID.\n",
    "    num_chunks (int): The number of JSON files (chunks) to read.\n",
    "    base_path (str, optional): The base path to the directory containing the JSON files. \n",
    "                               Defaults to 'wrapped_files/'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the processed data.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If no data files were found or all files were empty.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        json_file = os.path.join(base_path, f'{user_id}_music_{i}.json')\n",
    "        print(f\"Checking for file: {json_file}\")\n",
    "        \n",
    "        if not os.path.exists(json_file):\n",
    "            print(f\"File not found: {json_file}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Reading data from {json_file}\")\n",
    "        with open(json_file, 'r', encoding='utf-8') as file:\n",
    "            data_list = json.load(file)\n",
    "            all_data.extend(data_list)\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No data files were found or all were empty.\")\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['user_id'] = user_id\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    print(f\"Data read successfully for {len(df)} records.\")\n",
    "    return df\n",
    "\n",
    "def export_to_csv(df, user_id):\n",
    "    \"\"\"\n",
    "    Export data to a CSV file.\n",
    "\n",
    "    This function exports the provided DataFrame to a CSV file named with the user's ID.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data to be exported.\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    csv_file = f'{user_id}_listening_data.csv'\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Data exported to {csv_file}\")\n",
    "\n",
    "def track_unique_songs(df, unique_songs_file):\n",
    "    \"\"\"\n",
    "    Track unique songs in the given DataFrame.\n",
    "\n",
    "    This function ensures the DataFrame includes the necessary columns,\n",
    "    drops duplicates within the current DataFrame, and combines new unique songs\n",
    "    with existing unique songs from a CSV file. The combined unique songs are then\n",
    "    saved back to the CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data to be processed.\n",
    "    unique_songs_file (str): The file path to the CSV file where unique songs are stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure DataFrame includes necessary columns\n",
    "    required_columns = ['trackName', 'artistName', 'external_urls']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    \n",
    "    # Drop duplicates within the current DataFrame\n",
    "    new_unique_songs = df[required_columns].drop_duplicates()\n",
    "    print(f\"Tracking {len(new_unique_songs)} unique songs.\")\n",
    "    \n",
    "    try:\n",
    "        # Attempt to load existing unique songs from the CSV file\n",
    "        existing_unique_songs = pd.read_csv(unique_songs_file)\n",
    "        print(f\"Loaded {len(existing_unique_songs)} existing unique songs.\")\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, start with an empty DataFrame\n",
    "        existing_unique_songs = pd.DataFrame(columns=required_columns)\n",
    "        print(\"No existing unique songs file found. Starting fresh.\")\n",
    "    \n",
    "    # Combine new and existing unique songs\n",
    "    combined_unique_songs = pd.concat([existing_unique_songs, new_unique_songs]).drop_duplicates()\n",
    "    \n",
    "    # Save the combined DataFrame to the CSV file\n",
    "    combined_unique_songs.to_csv(unique_songs_file, index=False)\n",
    "    print(f\"Updated unique songs saved to {unique_songs_file}.\")\n",
    "\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    \"\"\"\n",
    "    Safely evaluate a string containing a Python literal or container display.\n",
    "\n",
    "    This function attempts to safely evaluate a string containing a Python literal\n",
    "    or container display (e.g., list, dictionary). If the evaluation fails due to\n",
    "    a ValueError or SyntaxError, the original value is returned.\n",
    "\n",
    "    Parameters:\n",
    "    val (str): The string to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "    object: The evaluated Python object, or the original value if evaluation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "\n",
    "def expand_artists_involved(df):\n",
    "    \"\"\"\n",
    "    Expand and standardize the list of artists involved in each track.\n",
    "\n",
    "    This function processes the 'artists_involved' column to ensure it is correctly evaluated as a list,\n",
    "    adds the main artist to this list if not already present, standardizes the artist names to lowercase,\n",
    "    and preserves the original artist names.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'artists_involved' and 'artistName' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Updated DataFrame with expanded and standardized artist names.\n",
    "    \"\"\"\n",
    "    print(\"Expanding and standardizing artists involved in each track\")\n",
    "\n",
    "    def safe_literal_eval(val):\n",
    "        try:\n",
    "            if isinstance(val, str):\n",
    "                return literal_eval(val)\n",
    "            return val\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "\n",
    "    def add_main_artist(row):\n",
    "        if isinstance(row['artists_involved'], list):\n",
    "            if row['artistName'] not in row['artists_involved']:\n",
    "                row['artists_involved'].append(row['artistName'])\n",
    "        else:\n",
    "            row['artists_involved'] = [row['artistName']]\n",
    "        return row\n",
    "\n",
    "    df = df.apply(add_main_artist, axis=1)\n",
    "    \n",
    "    df['standardized_artists'] = df['artists_involved'].apply(lambda x: [artist.lower() for artist in x])\n",
    "    df['standardized_artists_str'] = df['standardized_artists'].apply(lambda x: ', '.join(x))  # Convert lists to strings\n",
    "    df['original_artists'] = df['artists_involved']  # Preserve original names\n",
    "\n",
    "    print(\"Artists involved expanded and standardized successfully\")\n",
    "    return df \n",
    "\n",
    "\n",
    "def check_album_art_exists(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Check if the album art for a given artist exists in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check for album art. Defaults to 'albums'.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if album art exists, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = f\"{folder}/{artist_name}.jpg\"\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def fetch_album_art(artist_name, token, folder='albums'):\n",
    "    \"\"\"\n",
    "    Fetch album art for a given artist from Spotify API and save it to the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    token (str): Spotify API access token.\n",
    "    folder (str): The folder to save the album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    search_url = f'https://api.spotify.com/v1/search?q={artist_name}&type=artist&limit=1'\n",
    "    headers = {'Authorization': f'Bearer {token}'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['artists']['items']:\n",
    "        artist_info = data['artists']['items'][0]\n",
    "        if artist_info['images']:\n",
    "            image_url = artist_info['images'][0]['url']\n",
    "            image_response = requests.get(image_url)\n",
    "            with open(f\"{folder}/{artist_name}.jpg\", 'wb') as f:\n",
    "                f.write(image_response.content)\n",
    "            print(f\"Album art for {artist_name} saved.\")\n",
    "        else:\n",
    "            print(f\"No album art found for {artist_name}.\")\n",
    "    else:\n",
    "        print(f\"No artist found for {artist_name}.\")\n",
    "\n",
    "def ensure_album_art(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Ensure album art for a given artist exists, either by checking locally or fetching from Spotify API.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check and save album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    if not check_album_art_exists(artist_name, folder):\n",
    "        token = get_spotify_access_token(SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET)\n",
    "        fetch_album_art(artist_name, token, folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spotify API Integration</h3>\n",
    "<strong>Get Spotify Access Token:</strong> Function to obtain Spotify access token using client credentials.\n",
    "\n",
    "<strong>Get Song Details:</strong> Function to retrieve song details from Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_access_token(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Get Spotify access token using client credentials.\n",
    "\n",
    "    This function sends a request to the Spotify API to get an access token \n",
    "    using the client credentials (client ID and client secret). The token is \n",
    "    required for further API requests.\n",
    "\n",
    "    Parameters:\n",
    "    client_id (str): The Spotify client ID.\n",
    "    client_secret (str): The Spotify client secret.\n",
    "\n",
    "    Returns:\n",
    "    str: The access token used for further API requests.\n",
    "    \"\"\"\n",
    "    auth_url = 'https://accounts.spotify.com/api/token'\n",
    "    auth_response = requests.post(auth_url, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "    \n",
    "    # Parse the authentication response and extract access token\n",
    "    auth_response_data = auth_response.json()\n",
    "    return auth_response_data['access_token']\n",
    "\n",
    "def get_song_details(artist_name, track_name, access_token):\n",
    "    \"\"\"\n",
    "    Get song details from Spotify API using search query.\n",
    "\n",
    "    This function sends a search request to the Spotify API using the given \n",
    "    artist name and track name. It retrieves detailed information about the \n",
    "    song including album, release date, popularity, duration, track number, \n",
    "    album artwork, external URLs, artists involved, and genres.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    track_name (str): The name of the track.\n",
    "    access_token (str): The Spotify API access token.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing detailed information about the song. \n",
    "          None if no track is found.\n",
    "    \"\"\"\n",
    "    search_url = 'https://api.spotify.com/v1/search'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    query = f'artist:{quote(artist_name)} track:{quote(track_name)}'\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'type': 'track',\n",
    "        'limit': 1\n",
    "    }\n",
    "    \n",
    "    # Send request to Spotify API to search for the track\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    response_data = response.json()\n",
    "    \n",
    "    print(f\"Search query: artist:{artist_name} track:{track_name}\")\n",
    "    print(\"Search response data:\", response_data)\n",
    "    \n",
    "    if 'tracks' in response_data and response_data['tracks']['items']:\n",
    "        track_info = response_data['tracks']['items'][0]\n",
    "        \n",
    "        # Get artist details to fetch genres in batches\n",
    "        artist_ids = [artist['id'] for artist in track_info['artists']]\n",
    "        artist_genres = []\n",
    "\n",
    "        batch_size = 50\n",
    "        for i in range(0, len(artist_ids), batch_size):\n",
    "            batch_ids = artist_ids[i:i + batch_size]\n",
    "            artist_url = f\"https://api.spotify.com/v1/artists?ids={','.join(batch_ids)}\"\n",
    "            retries = 5\n",
    "            delay = 1\n",
    "            \n",
    "            while retries > 0:\n",
    "                artist_response = requests.get(artist_url, headers=headers)\n",
    "                \n",
    "                if artist_response.status_code == 200:\n",
    "                    try:\n",
    "                        artist_data = artist_response.json()['artists']\n",
    "                        for artist in artist_data:\n",
    "                            if 'genres' in artist:\n",
    "                                artist_genres.extend(artist['genres'])\n",
    "                        break  # Exit the retry loop if successful\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error decoding JSON for batch {batch_ids}: {e}\")\n",
    "                elif artist_response.status_code == 429:\n",
    "                    retry_after = int(artist_response.headers.get('Retry-After', delay))\n",
    "                    print(f\"Rate limited. Retrying after {retry_after} seconds.\")\n",
    "                    time.sleep(retry_after)\n",
    "                else:\n",
    "                    print(f\"Request failed with status code {artist_response.status_code}\")\n",
    "                \n",
    "                retries -= 1\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "            \n",
    "            if retries == 0:\n",
    "                print(f\"Failed to fetch genres for batch {batch_ids} after {retries} attempts.\")\n",
    "        \n",
    "        # Ensure the genres list is ordered and unique\n",
    "        artist_genres = sorted(set(artist_genres))\n",
    "        \n",
    "        # Check if album images and external URLs are present\n",
    "        album_artwork = track_info['album']['images'][0]['url'] if 'images' in track_info['album'] and track_info['album']['images'] else None\n",
    "        external_urls = track_info['external_urls']['spotify'] if 'external_urls' in track_info else None\n",
    "        \n",
    "        song_details = {\n",
    "            'spotify_id': track_info['id'],\n",
    "            'album': track_info['album']['name'],\n",
    "            'release_date': track_info['album']['release_date'],\n",
    "            'popularity': track_info['popularity'],\n",
    "            'duration_ms': track_info['duration_ms'],\n",
    "            'track_number': track_info['track_number'],\n",
    "            'album_artwork': album_artwork,\n",
    "            'external_urls': external_urls,\n",
    "            'artists_involved': [artist['name'] for artist in track_info['artists']],\n",
    "            'genres': artist_genres\n",
    "        }\n",
    "        \n",
    "        print(\"Song details:\", song_details)\n",
    "        return song_details\n",
    "    else:\n",
    "        print(\"No tracks found for the given query.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multi-Threading for Data Processing</h3>\n",
    "<strong>Worker Thread:</strong> Function for worker threads to process each song in the queue.\n",
    "\n",
    "<strong>Update Unique Songs:</strong> Function to update the unique songs table with Spotify information using threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_thread(queue, unique_songs, unique_songs_file, access_token, export_interval, lock, start_time):\n",
    "    \"\"\"\n",
    "    Worker function to process each song in the queue.\n",
    "\n",
    "    This function processes each song in the queue by fetching song details \n",
    "    from the Spotify API and updating the unique songs DataFrame. It also \n",
    "    periodically exports the updated DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    queue (Queue): The queue containing songs to be processed.\n",
    "    unique_songs (DataFrame): The DataFrame of unique songs.\n",
    "    unique_songs_file (str): The file path for the unique songs CSV.\n",
    "    access_token (str): The Spotify API access token.\n",
    "    export_interval (int): The interval at which the DataFrame is exported to the CSV file.\n",
    "    lock (Lock): The lock to ensure thread-safe operations.\n",
    "    start_time (float): The start time of the processing.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    while not queue.empty():\n",
    "        index, row = queue.get()\n",
    "        if pd.notna(row['spotify_id']):\n",
    "            queue.task_done()\n",
    "            continue\n",
    "        \n",
    "        artist_name = row['artistName']\n",
    "        track_name = row['trackName']\n",
    "        song_details = get_song_details(artist_name, track_name, access_token)\n",
    "        \n",
    "        if song_details:\n",
    "            with lock:\n",
    "                unique_songs.at[index, 'spotify_id'] = song_details['spotify_id']\n",
    "                unique_songs.at[index, 'album'] = song_details['album']\n",
    "                unique_songs.at[index, 'release_date'] = song_details['release_date']\n",
    "                unique_songs.at[index, 'popularity'] = song_details['popularity']\n",
    "                unique_songs.at[index, 'duration_ms'] = song_details['duration_ms']\n",
    "                unique_songs.at[index, 'track_number'] = song_details['track_number']\n",
    "                unique_songs.at[index, 'album_artwork'] = song_details['album_artwork']\n",
    "                unique_songs.at[index, 'external_urls'] = song_details['external_urls']\n",
    "                unique_songs.at[index, 'artists_involved'] = song_details['artists_involved']\n",
    "                unique_songs.at[index, 'genres'] = song_details['genres']\n",
    "        \n",
    "        if (index + 1) % export_interval == 0:\n",
    "            with lock:\n",
    "                print(f\"Exporting data at index {index}. Elapsed time: {time.time() - start_time:.2f} seconds.\")\n",
    "                unique_songs.to_csv(unique_songs_file, index=False)\n",
    "        \n",
    "        queue.task_done()\n",
    "\n",
    "def update_unique_songs(unique_songs_file='unique_songs.csv', export_interval=50):\n",
    "    \"\"\"\n",
    "    Main function to update unique songs table with Spotify info using threading.\n",
    "\n",
    "    This function loads the unique songs data, checks for missing columns, and \n",
    "    updates the table with Spotify information using multiple threads. The \n",
    "    updated table is periodically exported to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path for the unique songs CSV. Defaults to 'unique_songs.csv'.\n",
    "    export_interval (int, optional): The interval at which the DataFrame is exported to the CSV file. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load unique songs data from CSV file\n",
    "    print(f\"Loading unique songs from {unique_songs_file}\")\n",
    "    unique_songs = pd.read_csv(unique_songs_file)\n",
    "    print(f\"Loaded {len(unique_songs)} unique songs\")\n",
    "\n",
    "    # Check if the columns already exist, if not, create them\n",
    "    columns = ['spotify_id', 'album', 'release_date', 'popularity', 'duration_ms', 'track_number', 'album_artwork', 'external_urls', 'artists_involved', 'genre']\n",
    "    for column in columns:\n",
    "        if column not in unique_songs.columns:\n",
    "            unique_songs[column] = None\n",
    "\n",
    "    # Get Spotify access token\n",
    "    access_token = get_spotify_access_token(SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET)\n",
    "    \n",
    "    # Create a queue and add songs to be processed\n",
    "    q = queue.Queue()\n",
    "    for index, row in unique_songs.iterrows():\n",
    "        q.put((index, row))\n",
    "\n",
    "    # Create a lock for thread-safe operations\n",
    "    lock = threading.Lock()\n",
    "    start_time = time.time()\n",
    "    threads = []\n",
    "    for _ in range(10):  # Adjust number of threads as needed\n",
    "        thread = threading.Thread(target=worker_thread, args=(q, unique_songs, unique_songs_file, access_token, export_interval, lock, start_time))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    \n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    # Remove duplicates based on 'external_urls'\n",
    "    unique_songs = drop_duplicates_by_external_urls(unique_songs)\n",
    "    \n",
    "    # Final export\n",
    "    print(f\"Final export. Total time taken: {time.time() - start_time:.2f} seconds.\")\n",
    "    unique_songs.to_csv(unique_songs_file, index=False)\n",
    "    print(f\"Unique songs table updated with Spotify info and saved to {unique_songs_file}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Deduplication and Filling</h3>\n",
    "<strong>Drop Duplicates:</strong> Function to drop duplicate songs based on external URLs.\n",
    "\n",
    "<strong>Fill Song Info:</strong> Function to fill in song information from the unique songs database.\n",
    "\n",
    "<strong>Read Processed Data:</strong> Function to read processed listening data.\n",
    "\n",
    "<strong>Export Filled Data:</strong> Function to export filled listening data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates_by_external_urls(data):\n",
    "    \"\"\"\n",
    "    This function drops duplicate rows based on the 'external_urls' column, \n",
    "    but retains rows where 'external_urls' is blank.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing the song data with 'external_urls' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed based on 'external_urls'.\n",
    "    \"\"\"\n",
    "    # Identify rows where external_urls is not blank\n",
    "    non_blank_urls = data['external_urls'].notna()\n",
    "    \n",
    "    # Drop duplicates only where external_urls is not blank\n",
    "    data_non_blank = data[non_blank_urls].drop_duplicates(subset=['external_urls'])\n",
    "    \n",
    "    # Combine the non-duplicated rows with the rows where external_urls is blank\n",
    "    data_final = pd.concat([data_non_blank, data[~non_blank_urls]], ignore_index=True)\n",
    "    \n",
    "    return data_final\n",
    "\n",
    "def fill_song_info(listening_data, unique_songs):\n",
    "    \"\"\"\n",
    "    Fill in song information from the unique songs database.\n",
    "\n",
    "    This function filters out rows with 'unknown' artists in the listening data,\n",
    "    then merges the listening data with the unique songs database on 'artistName'\n",
    "    and 'trackName' to fill in additional song information.\n",
    "\n",
    "    Parameters:\n",
    "    listening_data (pandas.DataFrame): DataFrame containing the user's listening data.\n",
    "    unique_songs (pandas.DataFrame): DataFrame containing the unique songs database.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with filled in song information.\n",
    "    \"\"\"\n",
    "    # Filter out rows where artistName is 'unknown'\n",
    "    listening_data_filtered = listening_data[~listening_data['artistName'].str.lower().isin(['unknown', 'unknown artist'])]\n",
    "    # Merge listening data with unique songs data on 'artistName' and 'trackName'\n",
    "    filled_data = pd.merge(listening_data_filtered, unique_songs, on=['artistName', 'trackName'], how='left')\n",
    "    return filled_data\n",
    "\n",
    "def read_processed_data(user_id):\n",
    "    \"\"\"\n",
    "    Read processed listening data from a CSV file.\n",
    "\n",
    "    This function reads a CSV file containing the user's processed listening data\n",
    "    and returns it as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the user's processed listening data.\n",
    "    \"\"\"\n",
    "    csv_file = f'{user_id}_listening_data.csv'  # Example file path, adjust as needed\n",
    "    listening_data = pd.read_csv(csv_file)\n",
    "    return listening_data\n",
    "\n",
    "def export_filled_data(filled_data, user_id):\n",
    "    \"\"\"\n",
    "    Export filled listening data to a CSV file.\n",
    "\n",
    "    This function exports the provided DataFrame containing filled listening data\n",
    "    to a CSV file named with the user's ID.\n",
    "\n",
    "    Parameters:\n",
    "    filled_data (pandas.DataFrame): The DataFrame containing the filled listening data.\n",
    "    user_id (str): The user's ID.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    filled_csv_file = f'{user_id}_listening_data.csv'\n",
    "    filled_data.to_csv(filled_csv_file, index=False)\n",
    "    print(f\"Filled listening data exported to {filled_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Data Analysis & Visualization</h1></strong>\n",
    "<h3>Listening Time Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_listening_time_per_user(df):\n",
    "    \"\"\"\n",
    "    Calculate total listening time per user.\n",
    "\n",
    "    This function calculates the total listening time for each user by summing\n",
    "    the 'msPlayed' column grouped by 'user_id' and converting the time from\n",
    "    milliseconds to hours.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'user_id' and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening time per user in hours.\n",
    "    \"\"\"\n",
    "    print(\"Calculating total listening time per user\")\n",
    "    total_time = df.groupby('user_id')['msPlayed'].sum()\n",
    "    total_time_hours = total_time / (1000 * 60 * 60)  # Convert milliseconds to hours\n",
    "    print(\"Total listening time per user calculated\")\n",
    "    return total_time_hours\n",
    "\n",
    "def biggest_listening_date(df):\n",
    "    \"\"\"\n",
    "    Identify the biggest listening date and the total minutes listened to on that date.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the data by date,\n",
    "    sums the listening time ('msPlayed') for each date, and identifies the date with\n",
    "    the highest total listening time and the total listening time in minutes.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the biggest listening date and the total listening time on that date in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Identifying the biggest listening date\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    # Group by date and calculate the total listening time in milliseconds\n",
    "    total_listening_time_per_date = df.groupby(df['endTime'].dt.date)['msPlayed'].sum()\n",
    "    \n",
    "    # Identify the date with the highest total listening time\n",
    "    biggest_date = total_listening_time_per_date.idxmax()\n",
    "    \n",
    "    # Calculate the total listening time on that date in minutes\n",
    "    total_minutes_on_biggest_date = total_listening_time_per_date.max() / (1000 * 60)\n",
    "    \n",
    "    print(\"Biggest listening date identified\")\n",
    "    return biggest_date, total_minutes_on_biggest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_unique_counts(df):\n",
    "    \"\"\"\n",
    "    Calculate the number of unique songs, artists (using the expanded method), and albums.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with counts of unique songs, artists, and albums.\n",
    "    \"\"\"\n",
    "    # Unique songs\n",
    "    unique_songs = df['trackName'].nunique()\n",
    "\n",
    "    # Expand artists involved and calculate unique artists\n",
    "    df = expand_artists_involved(df)\n",
    "    unique_artists = df['standardized_artists'].explode().nunique()\n",
    "\n",
    "    # Unique albums\n",
    "    unique_albums = df['album'].nunique()\n",
    "\n",
    "    return {\n",
    "        'unique_songs': unique_songs,\n",
    "        'unique_artists': unique_artists,\n",
    "        'unique_albums': unique_albums\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Artist Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_artists_by_time(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate top listened-to artists by listening time.\n",
    "\n",
    "    This function expands the artists involved in each track, calculates the total\n",
    "    listening time for each artist by summing the 'msPlayed' column grouped by \n",
    "    'standardized_artists', and returns the top N artists based on their total \n",
    "    listening time, converted to seconds.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'standardized_artists' and 'msPlayed' columns.\n",
    "    top_n (int, optional): Number of top artists to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening time per artist in seconds, sorted in descending order.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating top {top_n} artists by listening time\")\n",
    "    df_expanded = df.explode('standardized_artists')\n",
    "    artist_time = df_expanded.groupby('standardized_artists')['msPlayed'].sum().sort_values(ascending=False).head(top_n)\n",
    "    artist_time_seconds = artist_time / 1000  # Convert milliseconds to seconds\n",
    "    print(\"Top artists by listening time calculated\")\n",
    "    return artist_time_seconds \n",
    "\n",
    "def top_artists_by_count(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate top listened-to artists by count.\n",
    "\n",
    "    This function expands the artists involved in each track, calculates the count\n",
    "    of occurrences for each artist using the 'standardized_artists' column, and returns\n",
    "    the top N artists based on their count.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'standardized_artists' column.\n",
    "    top_n (int, optional): Number of top artists to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the count of occurrences per artist, sorted in descending order.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating top {top_n} artists by count\")\n",
    "    df_expanded = df.explode('standardized_artists')\n",
    "    artist_count = df_expanded['standardized_artists'].value_counts().head(top_n)\n",
    "    print(\"Top artists by count calculated\")\n",
    "    return artist_count\n",
    "\n",
    "def top_artists_by_weighted_time(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate the top artists based on weighted listening time.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing artist data.\n",
    "        top_n (int): Number of top artists to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the top artists by weighted listening time.\n",
    "    \"\"\"\n",
    "    df_expanded = df.explode('standardized_artists')\n",
    "    \n",
    "    weighted_times = {}\n",
    "\n",
    "    for index, row in df_expanded.iterrows():\n",
    "        artist_name = row['artistName'].lower()\n",
    "        current_artist = row['standardized_artists']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        duration_ms = row['duration_ms']\n",
    "        \n",
    "        # Skip if percentage_listened or duration_ms is NaN\n",
    "        if pd.isna(percentage_listened) or pd.isna(duration_ms):\n",
    "            continue\n",
    "        \n",
    "        # Add check for empty or suspicious artist names\n",
    "        if not current_artist or not isinstance(current_artist, str):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        # Calculate actual listened time\n",
    "        listened_time = percentage_listened * duration_ms\n",
    "        \n",
    "        if artist_name in current_artist:\n",
    "            main_artist_weight = 0.5 * listened_time\n",
    "            other_artists_weight = 0.5 * listened_time / (len(row['artists_involved']) - 1) if len(row['artists_involved']) > 1 else 0\n",
    "            \n",
    "            # Add weight to main artist\n",
    "            if artist_name not in weighted_times:\n",
    "                weighted_times[artist_name] = 0\n",
    "            weighted_times[artist_name] += main_artist_weight\n",
    "            \n",
    "            # Add weight to other artists\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() != artist_name:\n",
    "                    if artist.lower() not in weighted_times:\n",
    "                        weighted_times[artist.lower()] = 0\n",
    "                    weighted_times[artist.lower()] += other_artists_weight\n",
    "        else:\n",
    "            equal_weight = listened_time / len(row['artists_involved'])\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() not in weighted_times:\n",
    "                    weighted_times[artist.lower()] = 0\n",
    "                weighted_times[artist.lower()] += equal_weight\n",
    "    \n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_times_df = pd.DataFrame.from_dict(weighted_times, orient='index', columns=['weighted_time'])\n",
    "    top_artists_weighted_time = weighted_times_df.sort_values(by='weighted_time', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_artists_weighted_time\n",
    "\n",
    "\n",
    "def top_artists_by_weighted_count(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate the top artists based on weighted listen counts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing artist data.\n",
    "        top_n (int): Number of top artists to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the top artists by weighted listens.\n",
    "    \"\"\"\n",
    "    df_expanded = df.explode('standardized_artists')\n",
    "    weighted_listens = {}\n",
    "\n",
    "    for index, row in df_expanded.iterrows():\n",
    "        artist_name = row['artistName'].lower()\n",
    "        current_artist = row['standardized_artists']\n",
    "        percentage_listened = row['percentage_listened']\n",
    "        \n",
    "        # Skip if percentage_listened is NaN\n",
    "        if pd.isna(percentage_listened):\n",
    "            continue\n",
    "        \n",
    "        # Add check for empty or suspicious artist names\n",
    "        if not current_artist or not isinstance(current_artist, str):\n",
    "            continue\n",
    "        \n",
    "        # Snap the percentage_listened to a maximum of 1\n",
    "        percentage_listened = min(percentage_listened / 100, 1)\n",
    "        \n",
    "        if artist_name in current_artist:\n",
    "            main_artist_weight = 0.5 * percentage_listened\n",
    "            other_artists_weight = 0.5 * percentage_listened / (len(row['artists_involved']) - 1) if len(row['artists_involved']) > 1 else 0\n",
    "            \n",
    "            # Add weight to main artist\n",
    "            if artist_name not in weighted_listens:\n",
    "                weighted_listens[artist_name] = 0\n",
    "            weighted_listens[artist_name] += main_artist_weight\n",
    "            \n",
    "            # Add weight to other artists\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() != artist_name:\n",
    "                    if artist.lower() not in weighted_listens:\n",
    "                        weighted_listens[artist.lower()] = 0\n",
    "                    weighted_listens[artist.lower()] += other_artists_weight\n",
    "        else:\n",
    "            equal_weight = percentage_listened / len(row['artists_involved'])\n",
    "            for artist in row['artists_involved']:\n",
    "                if artist.lower() not in weighted_listens:\n",
    "                    weighted_listens[artist.lower()] = 0\n",
    "                weighted_listens[artist.lower()] += equal_weight\n",
    "    \n",
    "    # Convert to a DataFrame for easy sorting and selection\n",
    "    weighted_listens_df = pd.DataFrame.from_dict(weighted_listens, orient='index', columns=['weighted_listens'])\n",
    "    top_artists_weighted_listens = weighted_listens_df.sort_values(by='weighted_listens', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_artists_weighted_listens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_artists_by_genre(df, genre, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify top artists within a specific genre.\n",
    "\n",
    "    This function filters the DataFrame by genre, sums the listening time ('minutesPlayed') for each artist,\n",
    "    and identifies the top artists within the genre based on the listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'genres', 'artistName', and 'msPlayed' columns.\n",
    "    genre (str): The genre to filter by.\n",
    "    top_n (int, optional): Number of top artists to return for the specified genre. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    list: List of the top artists within the specified genre based on listening time.\n",
    "    \"\"\"\n",
    "    print(f\"analyzing top artists for genre: {genre}\")\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_genre = df[df['genres'].apply(lambda x: genre in x)]\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_genre['minutesPlayed'] = df_genre['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    top_artists = df_genre.groupby('artistName')['minutesPlayed'].sum().nlargest(top_n).index.tolist()\n",
    "    \n",
    "    print(f\"top artists for genre {genre} analyzed\")\n",
    "    return top_artists\n",
    "\n",
    "\n",
    "def artist_attention_span(df):\n",
    "    \"\"\"\n",
    "    Calculate the attention span for different artists.\n",
    "\n",
    "    This function calculates the average percentage of each track listened to before skipping for each artist,\n",
    "    capping the percentage at 100 if it exceeds 100. It also returns the total listening time for each artist.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'artistName', 'duration_ms', and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Series containing the average percentage of tracks listened to for each artist, and a Series with the total listening time for each artist in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating music taste attention span for artists\")\n",
    "    \n",
    "    # Cap the percentage_listened values at 100\n",
    "    df['percentage_listened'] = df['percentage_listened'].apply(lambda x: min(x, 100))\n",
    "    \n",
    "    valid_entries = df.dropna(subset=['duration_ms', 'percentage_listened'])\n",
    "    \n",
    "    # Calculate average percentage listened for each artist\n",
    "    artist_span = valid_entries.groupby('artistName')['percentage_listened'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate total listening time for each artist\n",
    "    valid_entries['listened_time'] = valid_entries['duration_ms'] * (valid_entries['percentage_listened'] / 100)\n",
    "    artist_listened_time = valid_entries.groupby('artistName')['listened_time'].sum() / (1000 * 60)  # Convert milliseconds to minutes\n",
    "    \n",
    "    print(\"Music taste attention span for artists calculated\")\n",
    "    return artist_span, artist_listened_time\n",
    "\n",
    "def artist_diversity_growth(df):\n",
    "    \"\"\"\n",
    "    Calculate the growth in artist diversity over a period of time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month, and calculates the percentage growth in the number of distinct artists listened to between each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'standardized_artists' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the percentage growth in distinct artists per month.\n",
    "    \"\"\"\n",
    "    print(\"Calculating artist diversity growth\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df_expanded = df.explode('standardized_artists')\n",
    "    \n",
    "    artist_diversity = df_expanded.groupby(df_expanded['endTime'].dt.month)['standardized_artists'].nunique()\n",
    "    \n",
    "    artist_diversity_growth = artist_diversity.pct_change().fillna(0) * 100\n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    artist_diversity_growth.index = artist_diversity_growth.index.map(month_names)\n",
    "\n",
    "    print(\"Artist diversity growth calculated\")\n",
    "    return artist_diversity_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Music Taste and Habits Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_taste_per_month(df):\n",
    "    \"\"\"\n",
    "    Analyze top 5 music tastes per month.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, ensures 'artists_involved' is processed correctly,\n",
    "    expands the DataFrame to have one row per artist involved in each track, groups by month and artist,\n",
    "    sums the listening time ('msPlayed') for each artist, and identifies the top 5 artists per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'artistName', 'artists_involved', and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months as keys and lists of the top 5 artists for each month.\n",
    "    \"\"\"\n",
    "    print(\"analyzing music taste per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['artists_involved'] = df['artists_involved'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_artists(artists):\n",
    "        try:\n",
    "            return ast.literal_eval(artists)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['artists_involved'] = df['artists_involved'].apply(parse_artists)\n",
    "    \n",
    "    def add_main_artist(row):\n",
    "        if row['artistName'] not in row['artists_involved']:\n",
    "            row['artists_involved'].append(row['artistName'])\n",
    "        return row\n",
    "    \n",
    "    df = df.apply(add_main_artist, axis=1)\n",
    "    df_expanded = df.explode('artists_involved')\n",
    "    \n",
    "    music_taste = df_expanded.groupby([df_expanded['endTime'].dt.month, 'artists_involved'])['msPlayed'].sum().unstack().fillna(0)\n",
    "    \n",
    "    top_artists_per_month = {}\n",
    "    for month in music_taste.index:\n",
    "        top_artists = music_taste.loc[month].nlargest(5)\n",
    "        top_artists_per_month[month] = top_artists.index.tolist()\n",
    "\n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    formatted_output = {month_names[month]: artists for month, artists in top_artists_per_month.items()}\n",
    "\n",
    "    print(\"music taste per month analyzed\")\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def top_weighted_artists_per_month(df):\n",
    "    \"\"\"\n",
    "    Analyze top 5 weighted artists per month.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month and artist, calculates the weighted listening time ('msPlayed' * 'percentage_listened'), and identifies the top 5 artists per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'artistName', 'artists_involved', 'msPlayed', and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months as keys and lists of the top 5 artists for each month by weighted listening time.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top weighted artists per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['artists_involved'] = df['artists_involved'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_artists(artists):\n",
    "        try:\n",
    "            return ast.literal_eval(artists)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['artists_involved'] = df['artists_involved'].apply(parse_artists)\n",
    "    df['weighted_listening_time'] = df['msPlayed'] * df['percentage_listened'] / 100\n",
    "    \n",
    "    def add_main_artist(row):\n",
    "        if row['artistName'] not in row['artists_involved']:\n",
    "            row['artists_involved'].append(row['artistName'])\n",
    "        return row\n",
    "    \n",
    "    df = df.apply(add_main_artist, axis=1)\n",
    "    df_expanded = df.explode('artists_involved')\n",
    "    \n",
    "    top_artists_per_month = {}\n",
    "    for month in df_expanded['endTime'].dt.month.unique():\n",
    "        monthly_df = df_expanded[df_expanded['endTime'].dt.month == month]\n",
    "        top_artists = monthly_df.groupby('artists_involved')['weighted_listening_time'].sum().nlargest(5)\n",
    "        top_artists_per_month[month] = top_artists.index.tolist()\n",
    "    \n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    formatted_output = {month_names[month]: artists for month, artists in top_artists_per_month.items()}\n",
    "\n",
    "    print(\"top weighted artists per month analyzed\")\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def top_songs_by_plays_per_month(df):\n",
    "    \"\"\"\n",
    "    Analyze top 5 songs by unweighted plays per month.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups by month and track,\n",
    "    counts the number of plays for each track, and identifies the top 5 songs per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'trackName' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months as keys and lists of the top 5 tracks for each month by unweighted plays.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top songs by unweighted plays per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    top_songs_per_month = {}\n",
    "    for month in df['endTime'].dt.month.unique():\n",
    "        monthly_df = df[df['endTime'].dt.month == month]\n",
    "        top_songs = monthly_df['trackName'].value_counts().nlargest(5)\n",
    "        top_songs_per_month[month] = top_songs.index.tolist()\n",
    "    \n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    formatted_output = {month_names[month]: songs for month, songs in top_songs_per_month.items()}\n",
    "\n",
    "    print(\"top songs by unweighted plays per month analyzed\")\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def top_songs_by_weighted_time_per_month(df):\n",
    "    \"\"\"\n",
    "    Analyze top 5 songs by weighted listening time per month.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per artist involved in each track,\n",
    "    groups by month and track, calculates the weighted listening time ('msPlayed' * 'percentage_listened'), and identifies the top 5 songs per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', 'msPlayed', and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months as keys and lists of the top 5 tracks for each month by weighted listening time.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top songs by weighted listening time per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['weighted_listening_time'] = df['msPlayed'] * df['percentage_listened'] / 100\n",
    "    \n",
    "    top_songs_per_month = {}\n",
    "    for month in df['endTime'].dt.month.unique():\n",
    "        monthly_df = df[df['endTime'].dt.month == month]\n",
    "        top_songs = monthly_df.groupby('trackName')['weighted_listening_time'].sum().nlargest(5)\n",
    "        top_songs_per_month[month] = top_songs.index.tolist()\n",
    "    \n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    formatted_output = {month_names[month]: songs for month, songs in top_songs_per_month.items()}\n",
    "\n",
    "    print(\"top songs by weighted listening time per month analyzed\")\n",
    "    return formatted_output\n",
    "\n",
    "def monthly_listening_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze monthly listening patterns.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the DataFrame by month,\n",
    "    and calculates the total listening duration for each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the total listening duration for each month in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating monthly listening patterns\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    # Group by month and calculate total listening duration\n",
    "    df['month'] = df['endTime'].dt.to_period('M')\n",
    "    monthly_duration = df.groupby('month')['msPlayed'].sum()\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    monthly_duration = monthly_duration / (1000 * 60)\n",
    "    \n",
    "    print(\"Monthly listening patterns calculated\")\n",
    "    return monthly_duration\n",
    "\n",
    "\n",
    "def track_listening_duration_over_time(df):\n",
    "    \"\"\"\n",
    "    Calculate the total listening duration for each track over different time periods.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, groups the DataFrame by track and month,\n",
    "    and calculates the total listening duration for each track per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the total listening duration for each track per month in minutes.\n",
    "    \"\"\"\n",
    "    print(\"Calculating track listening duration over time\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    \n",
    "    # Group by track and month, and calculate total listening duration\n",
    "    df['month'] = df['endTime'].dt.to_period('M')\n",
    "    df_grouped = df.groupby(['trackName', 'month'])['msPlayed'].sum().reset_index()\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_grouped['listening_duration_minutes'] = df_grouped['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    print(\"Track listening duration over time calculated\")\n",
    "    return df_grouped\n",
    "\n",
    "def common_listening_days(df):\n",
    "    \"\"\"\n",
    "    Determine the most common listening days and times.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, calculates the frequency\n",
    "    of each day of the week in the listening data, and returns the counts of the most\n",
    "    common listening days.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' column.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the counts of the most common listening days.\n",
    "    \"\"\"\n",
    "    print(\"Determining the most common listening days and times\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    common_days = df['endTime'].dt.day_name().value_counts()\n",
    "    print(\"Most common listening days determined\")\n",
    "    return common_days\n",
    "\n",
    "\n",
    "def general_attention_span(df):\n",
    "    \"\"\"\n",
    "    Calculate the general attention span for all tracks.\n",
    "\n",
    "    This function calculates the average percentage of each track listened to before skipping,\n",
    "    capping the percentage at 100 if it exceeds 100. It also returns the count of times each song was listened to.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'duration_ms' and 'percentage_listened' columns.\n",
    "\n",
    "    Returns:\n",
    "    float: Average percentage of tracks listened to before skipping.\n",
    "    \"\"\"\n",
    "    print(\"Calculating general music taste attention span\")\n",
    "    \n",
    "    # Cap the percentage_listened values at 100\n",
    "    df['percentage_listened'] = df['percentage_listened'].apply(lambda x: min(x, 100))\n",
    "    \n",
    "    valid_entries = df.dropna(subset=['duration_ms', 'percentage_listened'])\n",
    "    attention_span = valid_entries['percentage_listened'].mean()\n",
    "    \n",
    "    print(\"General music taste attention span calculated\")\n",
    "    return attention_span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Genre Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_genres_per_month(df, top_n=5):\n",
    "    \"\"\"\n",
    "    Analyze top genres per month.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month and genre, sums the listening time ('msPlayed') for each genre, and identifies the top genres per month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'genres', and 'msPlayed' columns.\n",
    "    top_n (int): Number of top genres to return for each month. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with months as keys and lists of the top genres for each month.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top genres per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_expanded = df.explode('genres')\n",
    "    \n",
    "    genre_taste = df_expanded.groupby([df_expanded['endTime'].dt.month, 'genres'])['msPlayed'].sum().unstack().fillna(0)\n",
    "    \n",
    "    top_genres_per_month = {}\n",
    "    for month in genre_taste.index:\n",
    "        top_genres = genre_taste.loc[month].nlargest(top_n)\n",
    "        top_genres_per_month[month] = top_genres.index.tolist()\n",
    "\n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    formatted_output = {month_names[month]: genres for month, genres in top_genres_per_month.items()}\n",
    "\n",
    "    print(\"top genres per month analyzed\")\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def top_genres_for_year(df, top_n=5):\n",
    "    \"\"\"\n",
    "    Analyze top genres for the entire year.\n",
    "\n",
    "    This function expands the DataFrame to have one row per genre involved in each track,\n",
    "    sums the listening time ('minutesPlayed') for each genre for the entire year, and identifies the top genres.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'genres' and 'msPlayed' columns.\n",
    "    top_n (int, optional): Number of top genres to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    list: List of the top genres for the entire year based on listening time.\n",
    "    \"\"\"\n",
    "    print(\"analyzing top genres for the year\")\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_expanded = df.explode('genres')\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_expanded['minutesPlayed'] = df_expanded['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    genre_taste = df_expanded.groupby('genres')['minutesPlayed'].sum().nlargest(top_n)\n",
    "    top_genres = genre_taste.index.tolist()\n",
    "\n",
    "    print(\"top genres for the year analyzed\")\n",
    "    return top_genres\n",
    "\n",
    "def genre_popularity_over_time(df):\n",
    "    \"\"\"\n",
    "    Analyze genre popularity over time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by date and genre, and sums the listening time ('msPlayed') in minutes for each genre.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'genres', and 'msPlayed' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    \"\"\"\n",
    "    print(\"analyzing genre popularity over time\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_expanded = df.explode('genres')\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_expanded['minutesPlayed'] = df_expanded['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    genre_popularity = df_expanded.groupby([df_expanded['endTime'].dt.date, 'genres'])['minutesPlayed'].sum().unstack().fillna(0)\n",
    "    \n",
    "    print(\"genre popularity over time analyzed\")\n",
    "    return genre_popularity\n",
    "\n",
    "def top_tracks_by_genre(df, genre, top_n=5):\n",
    "    \"\"\"\n",
    "    Identify top tracks within a specific genre.\n",
    "\n",
    "    This function filters the DataFrame by genre, sums the listening time ('minutesPlayed') for each track,\n",
    "    and identifies the top tracks within the genre based on the listening time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime', 'trackName', 'minutesPlayed', and 'genres' columns.\n",
    "    genre (str): The genre to filter by.\n",
    "    top_n (int): Number of top tracks to return for the specified genre. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: List of tuples containing the top tracks within the specified genre and their corresponding listening times in minutes.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing top tracks for genre: {genre}\")\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        \"\"\"\n",
    "        Parse the genres column to ensure it contains valid genre data.\n",
    "\n",
    "        Args:\n",
    "            genres (str or list): The genre data to parse.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of genres.\n",
    "        \"\"\"\n",
    "        if isinstance(genres, list):\n",
    "            return genres\n",
    "        if pd.isna(genres) or genres == '[]':\n",
    "            return []\n",
    "        try:\n",
    "            # If genres is a string representation of a list\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    # Parse genres\n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    \n",
    "    df_genre = df[df['genres'].apply(lambda x: genre in x)]\n",
    "    \n",
    "    # Convert msPlayed to minutes\n",
    "    df_genre['minutesPlayed'] = df_genre['msPlayed'] / (1000 * 60)\n",
    "    \n",
    "    top_tracks = df_genre.groupby('trackName')['minutesPlayed'].sum().nlargest(top_n)\n",
    "    \n",
    "    print(f\"Top tracks for genre {genre} analyzed\")\n",
    "    return list(top_tracks.items())\n",
    "\n",
    "\n",
    "def genre_diversity_per_month(df):\n",
    "    \"\"\"\n",
    "    Calculate the diversity of user's music taste per month based on the number of distinct genres.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month, and counts the number of distinct genres listened to each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'genres' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the count of distinct genres per month.\n",
    "    \"\"\"\n",
    "    print(\"analyzing genre diversity per month\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_expanded = df.explode('genres')\n",
    "    \n",
    "    genre_diversity = df_expanded.groupby(df_expanded['endTime'].dt.month)['genres'].nunique()\n",
    "    \n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    genre_diversity.index = genre_diversity.index.map(month_names)\n",
    "    \n",
    "    print(\"genre diversity per month analyzed\")\n",
    "    return genre_diversity\n",
    "\n",
    "def genre_diversity_growth(df):\n",
    "    \"\"\"\n",
    "    Calculate the growth in genre diversity over a period of time.\n",
    "\n",
    "    This function converts the 'endTime' column to datetime, expands the DataFrame to have one row per genre involved in each track,\n",
    "    groups by month, and calculates the percentage growth in the number of distinct genres listened to between each month.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the listening data with 'endTime' and 'genres' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: Series containing the percentage growth in distinct genres per month.\n",
    "    \"\"\"\n",
    "    print(\"Calculating genre diversity growth\")\n",
    "    df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "    df['genres'] = df['genres'].replace({pd.NA: '[]'})\n",
    "    \n",
    "    def parse_genres(genres):\n",
    "        try:\n",
    "            return ast.literal_eval(genres)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    \n",
    "    df['genres'] = df['genres'].apply(parse_genres)\n",
    "    df_expanded = df.explode('genres')\n",
    "    \n",
    "    genre_diversity = df_expanded.groupby(df_expanded['endTime'].dt.month)['genres'].nunique()\n",
    "    \n",
    "    genre_diversity_growth = genre_diversity.pct_change().fillna(0) * 100\n",
    "    month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    genre_diversity_growth.index = genre_diversity_growth.index.map(month_names)\n",
    "\n",
    "    print(\"Genre diversity growth calculated\")\n",
    "    return genre_diversity_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genre_popularity_heatmap(genre_popularity, top_n=20):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of genre popularity over time.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    top_n (int): Number of top genres to display in the heatmap. Default is 20.\n",
    "    \"\"\"\n",
    "    # Sum listening time for each genre and select top N genres\n",
    "    top_genres = genre_popularity.sum().nlargest(top_n).index\n",
    "    genre_popularity_top = genre_popularity[top_genres]\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(genre_popularity_top.T, cmap=\"YlGnBu\", cbar_kws={'label': 'Listening Time (minutes)'})\n",
    "    plt.title('Top Genres Popularity Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Genre')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_top_genres_line(genre_popularity, top_n=5):\n",
    "    \"\"\"\n",
    "    Plot a line chart of the top genres over time.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "    top_n (int): Number of top genres to display in the line plot. Default is 5.\n",
    "    \"\"\"\n",
    "    top_genres = genre_popularity.sum().nlargest(top_n).index\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for genre in top_genres:\n",
    "        plt.plot(genre_popularity.index, genre_popularity[genre], label=genre)\n",
    "    plt.title(f'Top {top_n} Genres Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Listening Time (minutes)')\n",
    "    plt.legend(title='Genre')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def genre_summary_statistics(genre_popularity):\n",
    "    \"\"\"\n",
    "    Generate summary statistics for genre popularity.\n",
    "\n",
    "    Parameters:\n",
    "    genre_popularity (pandas.DataFrame): DataFrame containing the summed listening time in minutes for each genre over time.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing summary statistics for genre popularity.\n",
    "    \"\"\"\n",
    "    total_listening_time = genre_popularity.sum()\n",
    "    most_popular_genre = total_listening_time.idxmax()\n",
    "    least_popular_genre = total_listening_time.idxmin()\n",
    "\n",
    "    summary = {\n",
    "        \"Most Popular Genre\": most_popular_genre,\n",
    "        \"Total Listening Time of Most Popular Genre (minutes)\": total_listening_time[most_popular_genre],\n",
    "        \"Least Popular Genre\": least_popular_genre,\n",
    "        \"Total Listening Time of Least Popular Genre (minutes)\": total_listening_time[least_popular_genre]\n",
    "    }\n",
    "\n",
    "    print(\"summary statistics for genre popularity generated\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Frame, PageBreak\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from reportlab.platypus import Paragraph, Image, SimpleDocTemplate, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def generate_report():\n",
    "    \"\"\"\n",
    "    Function to create a button and text input for generating a PDF report based on user ID.\n",
    "    This version includes the introduction paragraph and PDF generation logic.\n",
    "    \"\"\"\n",
    "    def on_generate_button_click(b):\n",
    "        user_id = user_id_input.value\n",
    "        create_pdf_report(user_id)\n",
    "        print(f\"Report generated for user ID: {user_id}\")\n",
    "\n",
    "    # Create text input widget for user ID\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    generate_button = widgets.Button(description=\"Generate Report\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    generate_button.on_click(on_generate_button_click)\n",
    "\n",
    "    # Display the input field and button\n",
    "    display(user_id_input, generate_button)\n",
    "\n",
    "def create_pdf_report(user_id='ezra'):\n",
    "    \"\"\"\n",
    "    Creates a PDF report for the given user ID with an introduction paragraph and analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    user_id (str): The user ID for which to generate the report.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def save_partial_pdf(doc, elements, part):\n",
    "        doc.build(elements)\n",
    "        elements.clear()\n",
    "        elements.append(PageBreak())\n",
    "        print(f\"Part {part} of the PDF saved.\")\n",
    "\n",
    "    # Set up the PDF document\n",
    "    file_name = f\"{user_id}_spotify_report.pdf\"\n",
    "    document_title = \"Spotify Re-Wrapped 2024\"\n",
    "    intro_text = (\n",
    "        \"Spotify Wrapped for 2024 didn’t quite hit the mark, so I decided to take matters into my own hands. \"\n",
    "        \"This project dives into my actual listening data to get a better picture of my music tastes. \"\n",
    "        \"By analyzing various aspects of my Spotify history, I can uncover patterns, preferences, and trends that \"\n",
    "        \"Spotify's summary might have missed. From listening times and favorite artists to genre distributions, \"\n",
    "        \"this project aims to create a more accurate and personalized Spotify Re-Wrapped experience.\"\n",
    "    )\n",
    "\n",
    "    # Read the user's listening data from a CSV file\n",
    "    file_path = f\"{user_id}_listening_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Expand and standardize artists involved\n",
    "    df = expand_artists_involved(df)\n",
    "\n",
    "    # Perform analysis\n",
    "    #general\n",
    "    total_time_hours = total_listening_time_per_user(df)\n",
    "    biggest_date, total_minutes_on_biggest_date = biggest_listening_date(df)\n",
    "    unique_counts = calculate_unique_counts(df)\n",
    "    \n",
    "    #artist\n",
    "    top_artists_time = top_artists_by_time(df)\n",
    "    top_artists_count = top_artists_by_count(df)\n",
    "    top_artists_weighted_time = top_artists_by_weighted_time(df)\n",
    "    top_artists_weighted_count = top_artists_by_weighted_count(df)\n",
    "\n",
    "    #genre\n",
    "    top_genres_year = top_genres_for_year(df)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # top_genre_artists = top_artists_by_genre(df, 'Pop')\n",
    "    # artist_attention = artist_attention_span(df)\n",
    "    # artist_diversity = artist_diversity_growth(df)\n",
    "    # music_taste_month = music_taste_per_month(df)\n",
    "    # weighted_artists_month = top_weighted_artists_per_month(df)\n",
    "    # songs_by_plays_month = top_songs_by_plays_per_month(df)\n",
    "    # weighted_songs_month = top_songs_by_weighted_time_per_month(df)\n",
    "    # monthly_patterns = monthly_listening_patterns(df)\n",
    "    # track_duration_over_time = track_listening_duration_over_time(df)\n",
    "    # common_days = common_listening_days(df)\n",
    "    # attention_span = general_attention_span(df)\n",
    "    # genres_per_month = top_genres_per_month(df)\n",
    "    # genre_popularity = genre_popularity_over_time(df)\n",
    "    # top_tracks_genre = top_tracks_by_genre(df, 'Pop')\n",
    "    # genre_diversity = genre_diversity_per_month(df)\n",
    "    # genre_growth = genre_diversity_growth(df)\n",
    "    \n",
    "    # # Ensure genre_popularity is not empty before calculating summary statistics\n",
    "    # genre_summary = {}\n",
    "    # if not genre_popularity.empty:\n",
    "    #     genre_summary = genre_summary_statistics(genre_popularity)\n",
    "\n",
    "    # # Create visualizations if genre_popularity is not empty\n",
    "    # if not genre_popularity.empty:\n",
    "    #     plot_genre_popularity_heatmap(genre_popularity)\n",
    "    #     plot_top_genres_line(genre_popularity)\n",
    "\n",
    "    # Create the PDF document using SimpleDocTemplate\n",
    "    doc = SimpleDocTemplate(file_name, pagesize=letter)\n",
    "    \n",
    "    # Define styles for the document\n",
    "    styles = getSampleStyleSheet()\n",
    "    header_style = styles['Title']\n",
    "    body_style = styles['BodyText']\n",
    "    \n",
    "    # Create the header and introduction paragraph\n",
    "    header = Paragraph(document_title, header_style)\n",
    "    introduction = Paragraph(intro_text, body_style)\n",
    "\n",
    "    # Format the message \n",
    "    total_listening_time_message = f\"You listened to <b>{total_time_hours[user_id]:.2f}</b> hours of music this year.\"\n",
    "    top_day_message = f\"You listened to the most music on <b>{biggest_date.strftime('%B %d, %Y')}</b>! A whole <b>{total_minutes_on_biggest_date:.2f}</b> minutes of music!\"\n",
    "    unique_counts_msg = f\"You listened to <b>{unique_counts['unique_songs']} unique songs</b> this year. That's music from <b>{unique_counts['unique_artists']} different artists</b> and on <b>{unique_counts['unique_albums']} different albums</b>! Way to go!\"\n",
    "    \n",
    "    formatted_artists_time = [] \n",
    "    for artist, time in top_artists_time.items(): \n",
    "        minutes = time / 60 \n",
    "        hours = time / 3600 \n",
    "        formatted_artists_time.append(f\"{artist.title()} - {minutes:.2f} min. ({hours:.2f} hr.)\")\n",
    "    formatted_artists_time = \"<br/>\".join(formatted_artists_time)\n",
    "\n",
    "    formatted_artists_count = [] \n",
    "    for artist, count in top_artists_count.items(): \n",
    "        formatted_artists_count.append(f\"{artist.title()} - {count} plays.\")\n",
    "    formatted_artists_count = \"<br/>\".join(formatted_artists_count)\n",
    "\n",
    "\n",
    "    formatted_artists_time_w = []\n",
    "    if isinstance(top_artists_weighted_time, pd.DataFrame):\n",
    "        for index, row in top_artists_weighted_time.iterrows():\n",
    "            artist = index\n",
    "            time = row['weighted_time']\n",
    "            minutes = time / (1000 * 60)  # Convert from milliseconds to minutes\n",
    "            hours = time / (1000 * 60 * 60)  # Convert from milliseconds to hours\n",
    "            formatted_artists_time_w.append(f\"{artist.title()} - {minutes:.2f} weighted min. ({hours:.2f} weighted hr.)\")\n",
    "    else:\n",
    "        for artist, time in top_artists_weighted_time.items():\n",
    "            minutes = time / (1000 * 60)  # Convert from milliseconds to minutes\n",
    "            hours = time / (1000 * 60 * 60)  # Convert from milliseconds to hours\n",
    "            formatted_artists_time_w.append(f\"{artist.title()} - {minutes:.2f} weighted min. ({hours:.2f} weighted hr.)\")\n",
    "    formatted_artists_time_w = \"<br/>\".join(formatted_artists_time_w)\n",
    "\n",
    "    formatted_artists_count_w = []\n",
    "    if isinstance(top_artists_weighted_count, pd.DataFrame):\n",
    "        for index, row in top_artists_weighted_count.iterrows():\n",
    "            artist = index\n",
    "            count = row['weighted_listens']\n",
    "            formatted_artists_count_w.append(f\"{artist.title()} - {count:.2f} weighted plays\")\n",
    "    else:\n",
    "        for artist, count in top_artists_weighted_count.items():\n",
    "            formatted_artists_count_w.append(f\"{artist.title()} - {count:.2f} weighted plays\")\n",
    "    formatted_artists_count_w = \"<br/>\".join(formatted_artists_count_w)\n",
    "\n",
    "\n",
    "    formatted_genres_year = []\n",
    "    for genre in top_genres_year:\n",
    "        formatted_genres_year.append(f\"- {genre.title()}\")\n",
    "    formatted_genres_year = \"<br/>\".join(formatted_genres_year)\n",
    "\n",
    "    # Initialize a list to store formatted tracks by genre\n",
    "    formatted_genre_tracks = []\n",
    "\n",
    "    # Loop through the top 5 genres and get the top tracks for each\n",
    "    for genre in top_genres_year[:5]:\n",
    "        top_tracks_genre = top_tracks_by_genre(df, genre)\n",
    "        \n",
    "        formatted_tracks = []\n",
    "        for track, minutes in top_tracks_genre:\n",
    "            formatted_tracks.append(f\"{track} - {minutes:.2f} min.\")\n",
    "        formatted_tracks = \"<br/>\".join(formatted_tracks)\n",
    "        formatted_genre_tracks.append(f\"<b>Top Tracks in {genre.title()}:</b><br/>{formatted_tracks}\")\n",
    "\n",
    "    # Combine all the formatted tracks by genre into a single string\n",
    "    formatted_genre_tracks = \"<br/><br/>\".join(formatted_genre_tracks)\n",
    "\n",
    "    # Print the formatted genre tracks to verify\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Assemble the elements\n",
    "    elements = [header, introduction, Spacer(1, 12)]\n",
    "    part = 1\n",
    "\n",
    "    # Add analysis results to the PDF in sections\n",
    "    analysis_results = [\n",
    "        #general\n",
    "        (\"<b>Total Listening Time per User (in hours):</b>\", total_listening_time_message),\n",
    "        (\"<b>Biggest Listening Date and Total Minutes Listened:</b>\", top_day_message),\n",
    "        (\"<b>Number of Unique Songs, Artists, and Albums:</b>\", unique_counts_msg),\n",
    "        \n",
    "        #artists\n",
    "        (\"<b>Top Artists by Listening Time:</b>\", formatted_artists_time),\n",
    "        (\"<b>Top Artists by Count:</b>\", formatted_artists_count),\n",
    "        (\"<b>Top Artists by Weighted Listening Time:</b>\", formatted_artists_time_w),\n",
    "        (\"<b>Top Artists by Weighted Count:</b>\", formatted_artists_count_w),\n",
    "        (\"<b>Top Genres for the Year:</b>\", formatted_genres_year),\n",
    "        (\"<b>Top Tracks by Genre:</b>\", formatted_genre_tracks),\n",
    "\n",
    "        # (\"**Artist Attention Span:**\", artist_attention[0].to_string()),\n",
    "        # (\"**Artist Listening Time (in minutes):**\", artist_attention[1].to_string()),\n",
    "        # (\"**Artist Diversity Growth:**\", artist_diversity.to_string()),\n",
    "        # (\"**Music Taste per Month:**\", str(music_taste_month)),\n",
    "        # (\"**Top Weighted Artists per Month:**\", str(weighted_artists_month)),\n",
    "        # (\"**Top Songs by Plays per Month:**\", str(songs_by_plays_month)),\n",
    "        # (\"**Top Songs by Weighted Listening Time per Month:**\", str(weighted_songs_month)),\n",
    "        # (\"**Monthly Listening Patterns (in minutes):**\", monthly_patterns.to_string()),\n",
    "        # (\"**Track Listening Duration Over Time:**\", track_duration_over_time.to_string()),\n",
    "        # (\"**Common Listening Days:**\", common_days.to_string()),\n",
    "        # (\"**General Attention Span:**\", f\"{attention_span}%\"),\n",
    "        # (\"**Top Genres per Month:**\", str(genres_per_month)),\n",
    "        # (\"**Genre Popularity Over Time:**\", genre_popularity.to_string()),\n",
    "        # (\"**Top Tracks by Genre (Pop):**\", str(top_tracks_genre)),\n",
    "        # (\"**Genre Diversity per Month:**\", genre_diversity.to_string()),\n",
    "        # (\"**Genre Diversity Growth:**\", genre_growth.to_string()),\n",
    "        # (\"**Genre Summary Statistics:**\", str(genre_summary))\n",
    "    ]\n",
    "\n",
    "    for idx, (title, content) in enumerate(analysis_results):\n",
    "        elements.append(Paragraph(\"<br/>\" + title, body_style))\n",
    "        elements.append(Paragraph(content, body_style))\n",
    "        \n",
    "    #     # Save the PDF after every 5 sections\n",
    "    #     if (idx + 1) % 5 == 0:\n",
    "    #         save_partial_pdf(doc, elements, part)\n",
    "    #         part += 1\n",
    "\n",
    "    # Save the final part of the PDF\n",
    "    save_partial_pdf(doc, elements, part)\n",
    "\n",
    "\n",
    "\n",
    "def get_unique_genres(df):\n",
    "    \"\"\"\n",
    "    Get unique genres from the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the listening data.\n",
    "\n",
    "    Returns:\n",
    "        set: Set containing unique genres.\n",
    "    \"\"\"\n",
    "    unique_genres = set()\n",
    "    for genres_list in df['genres']:\n",
    "        for genre in genres_list:\n",
    "            unique_genres.add(genre)\n",
    "    return unique_genres\n",
    "\n",
    "\n",
    "# Call the function to display the input fields and button for generating a report\n",
    "generate_report()\n",
    "\n",
    "#create_pdf_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Paragraph, Image, SimpleDocTemplate, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import os\n",
    "\n",
    "def ensure_album_art(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Ensure album art for a given artist exists, either by checking locally or fetching from Spotify API.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check and save album art. Defaults to 'albums'.\n",
    "    \"\"\"\n",
    "    sanitized_artist_name = artist_name.replace(' ', '_').lower()\n",
    "    if not check_album_art_exists(sanitized_artist_name, folder):\n",
    "        token = get_spotify_token()\n",
    "        fetch_album_art(artist_name, token, folder)\n",
    "\n",
    "def check_album_art_exists(artist_name, folder='albums'):\n",
    "    \"\"\"\n",
    "    Check if the album art for a given artist exists in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    artist_name (str): The name of the artist.\n",
    "    folder (str): The folder to check for album art. Defaults to 'albums'.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if album art exists, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = f\"{folder}/{artist_name}.jpg\"\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def generate_artist_elements_with_images(top_artists_time):\n",
    "    \"\"\"\n",
    "    Generate a list of reportlab Flowable elements with album art and listening time for each artist.\n",
    "\n",
    "    Parameters:\n",
    "    top_artists_time (pandas.Series): A Series where the index contains artist names and the values contain the listening times.\n",
    "\n",
    "    Returns:\n",
    "    list: List of Flowable elements with album art and listening times for each artist.\n",
    "    \"\"\"\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    style = styles['Normal']\n",
    "    \n",
    "    for artist, time in top_artists_time.items():\n",
    "        sanitized_artist_name = artist.replace(' ', '_').lower()\n",
    "        ensure_album_art(artist)\n",
    "        album_art_path = f\"albums/{sanitized_artist_name}.jpg\"\n",
    "        if os.path.isfile(album_art_path):\n",
    "            img = Image(album_art_path, width=50, height=50)\n",
    "        else:\n",
    "            img = Image('placeholder.jpg', width=50, height=50)\n",
    "        \n",
    "        artist_text = f\"{artist}: {time:.2f} seconds\"\n",
    "        elements.append(img)\n",
    "        elements.append(Paragraph(artist_text, style))\n",
    "        elements.append(Spacer(1, 12))  # Add some space between entries\n",
    "    \n",
    "    return elements\n",
    "\n",
    "# Assuming 'df' is your DataFrame with Spotify listening data\n",
    "top_artists_time = top_artists_by_time(df)\n",
    "artist_elements = generate_artist_elements_with_images(top_artists_time)\n",
    "\n",
    "# Example usage in a SimpleDocTemplate\n",
    "doc = SimpleDocTemplate(\"example_report.pdf\", pagesize=letter)\n",
    "doc.build(artist_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h1>Main Functions</h1></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Process and Track Songs:</strong> Function to process raw listening data, add songs to the unique_songs file, and save the new CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def process_and_track_songs(base_path='../wrapped_files/', unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Process the raw listening data, track unique songs, and save to CSV.\n",
    "\n",
    "    This function processes the raw listening data by reading and combining multiple chunks,\n",
    "    adds all unique songs into the unique_songs file, and saves the processed data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    base_path (str, optional): The base path to the directory containing the raw listening data files. \n",
    "                               Defaults to '../wrapped_files/'.\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_process_button_click(b):\n",
    "        user_id = user_id_input.value\n",
    "        num_chunks = num_chunks_input.value\n",
    "\n",
    "        try:\n",
    "            df = read_and_process_data(user_id, num_chunks, base_path)\n",
    "            export_to_csv(df, user_id)\n",
    "            track_unique_songs(df, unique_songs_file)\n",
    "\n",
    "            print(\"Data processing complete!\")\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "    # Create text input widgets for user ID and number of chunks\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "    num_chunks_input = widgets.IntText(description=\"Num Chunks:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    process_button = widgets.Button(description=\"Process and Export Data\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    process_button.on_click(on_process_button_click)\n",
    "\n",
    "    # Display the input fields and button\n",
    "    display(user_id_input, num_chunks_input, process_button)\n",
    "\n",
    "# Call the function to display the widgets and set up the processing\n",
    "process_and_track_songs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_unique_songs_data(unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Update the unique songs table with Spotify info.\n",
    "\n",
    "    This function updates the unique songs table with information from Spotify.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_update_button_click(b):\n",
    "        update_unique_songs(unique_songs_file)\n",
    "        print(\"Unique songs table updated with Spotify info.\")\n",
    "\n",
    "    # Create a button widget for updating unique songs\n",
    "    update_button = widgets.Button(description=\"Update Unique Songs\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    update_button.on_click(on_update_button_click)\n",
    "\n",
    "    # Display the button\n",
    "    display(update_button)\n",
    "\n",
    "# Call the function to set up the button for updating unique songs\n",
    "update_unique_songs_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the unique songs database\n",
    "unique_songs_file = 'unique_songs.csv'\n",
    "unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "# Sort the database by artistName\n",
    "sorted_unique_songs = unique_songs.sort_values(by='artistName')\n",
    "\n",
    "# Save the sorted database to a new CSV file\n",
    "sorted_unique_songs_file = 'sorted_unique_songs.csv'\n",
    "sorted_unique_songs.to_csv(sorted_unique_songs_file, index=False)\n",
    "\n",
    "print(f\"Sorted unique songs database saved to {sorted_unique_songs_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "def process_filled_listening_data(unique_songs_file='unique_songs.csv'):\n",
    "    \"\"\"\n",
    "    Load unique songs data, get user ID, read processed listening data,\n",
    "    fill in song info, calculate percentage listened, remove empty genre column,\n",
    "    and export to CSV.\n",
    "\n",
    "    This function loads unique songs data, gets the user ID, reads the processed listening data,\n",
    "    fills in song info from the unique songs database, calculates the percentage listened for each track,\n",
    "    checks and removes the empty 'genre' column, and exports the filled data to a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    unique_songs_file (str, optional): The file path to the CSV file where unique songs are stored. \n",
    "                                       Defaults to 'unique_songs.csv'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def on_process_button_click(b):\n",
    "        unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "        user_id = user_id_input.value\n",
    "        try:\n",
    "            listening_data = read_processed_data(user_id)\n",
    "            \n",
    "            filled_listening_data = fill_song_info(listening_data, unique_songs)\n",
    "\n",
    "            # Check if 'duration_ms' column is present\n",
    "            if 'duration_ms' not in filled_listening_data.columns:\n",
    "                print(\"Warning: 'duration_ms' column is missing in filled_listening_data.\")\n",
    "                return\n",
    "            \n",
    "            # Calculate percentage listened\n",
    "            filled_listening_data['percentage_listened'] = (filled_listening_data['msPlayed'] / filled_listening_data['duration_ms']) * 100\n",
    "            \n",
    "            # Check and remove the empty 'genre' column if it exists and is empty\n",
    "            if 'genre' in filled_listening_data.columns and filled_listening_data['genre'].isnull().all():\n",
    "                filled_listening_data = filled_listening_data.drop(columns=['genre'])\n",
    "            \n",
    "            export_filled_data(filled_listening_data, user_id)\n",
    "\n",
    "            print(\"Data processing complete!\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Processed data file not found for user ID: {user_id}\")\n",
    "\n",
    "    # Create text input widgets for user ID\n",
    "    user_id_input = widgets.Text(description=\"User ID:\")\n",
    "\n",
    "    # Create a button widget\n",
    "    process_button = widgets.Button(description=\"Process Filled Listening Data\")\n",
    "\n",
    "    # Link the button to the nested function\n",
    "    process_button.on_click(on_process_button_click)\n",
    "\n",
    "    # Display the input fields and button\n",
    "    display(user_id_input, process_button)\n",
    "\n",
    "# Call the function to display the input fields and button for processing filled listening data\n",
    "process_filled_listening_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Color Generation Functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a random color\n",
    "def generate_random_color():\n",
    "    color = (random.randint(100, 255), random.randint(100, 255), random.randint(100, 255))\n",
    "    print(f\"Generated random color: {color}\")\n",
    "    return color\n",
    "\n",
    "# Function to generate a color close to a given color\n",
    "def generate_similar_color(color, variance=50):\n",
    "    r = min(max(color[0] + random.randint(-variance, variance), 0), 255)\n",
    "    g = min(max(color[1] + random.randint(-variance, variance), 0), 255)\n",
    "    b = min(max(color[2] + random.randint(-variance, variance), 0), 255)\n",
    "    similar_color = (r, g, b)\n",
    "    print(f\"Generated color similar to {color}: {similar_color}\")\n",
    "    return similar_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Abstract Background Generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an abstract background with dynamic colors\n",
    "def generate_abstract_background(width=1080, height=1920):\n",
    "    print(f\"Generating abstract background of size {width}x{height}\")\n",
    "    start_color = generate_random_color()\n",
    "    end_color = generate_similar_color(start_color)\n",
    "    \n",
    "    # Create a gradient based on the generated colors\n",
    "    gradient = np.linspace(start_color, end_color, width).astype(int)\n",
    "    gradient_cmap = plt.cm.colors.ListedColormap(gradient / 255.0)\n",
    "\n",
    "    x = np.linspace(-5, 5, width)\n",
    "    y = np.linspace(-5, 5, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    Z = np.sin(X**2 + Y**2) * np.cos(Y**2 - X**2)\n",
    "    \n",
    "    plt.figure(figsize=(width / 100, height / 100), dpi=100)\n",
    "    plt.imshow(Z, cmap=gradient_cmap, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('abstract_background.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    background = Image.open('abstract_background.png')\n",
    "    background = background.resize((width, height))\n",
    "    print(\"Abstract background generated and saved as 'abstract_background.png'\")\n",
    "    return background\n",
    "\n",
    "# Function to generate Perlin noise\n",
    "def generate_perlin_noise(width, height, scale=100, seed=random.randint(0,500)):\n",
    "    print(f\"Generating Perlin noise of size {width}x{height} with scale {scale} and seed {seed}\")\n",
    "    shape = (width, height)\n",
    "    world = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            world[i][j] = noise.pnoise2(i / scale, j / scale, octaves=6, persistence=0.5, lacunarity=2.0, repeatx=1024, repeaty=1024, base=seed)\n",
    "    \n",
    "    norm_world = (world - np.min(world)) / (np.max(world) - np.min(world))\n",
    "    print(\"Perlin noise generated\")\n",
    "    return norm_world\n",
    "\n",
    "# Function to generate an abstract background with Perlin noise\n",
    "def generate_abstract_background_with_noise(width=1080, height=1920):\n",
    "    print(f\"Generating abstract background with Perlin noise of size {width}x{height}\")\n",
    "    noise_pattern = generate_perlin_noise(width, height)\n",
    "    \n",
    "    start_color = generate_random_color()\n",
    "    end_color = generate_similar_color(start_color)\n",
    "    gradient = np.linspace(start_color, end_color, width).astype(int)\n",
    "    gradient_cmap = plt.cm.colors.ListedColormap(gradient / 255.0)\n",
    "\n",
    "    plt.figure(figsize=(width / 100, height / 100), dpi=100)\n",
    "    plt.imshow(noise_pattern, cmap=gradient_cmap, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('abstract_background_with_noise.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    background = Image.open('abstract_background_with_noise.png')\n",
    "    background = background.resize((width, height))\n",
    "    print(\"Abstract background with Perlin noise generated and saved as 'abstract_background_with_noise.png'\")\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Text Drawing Function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw wrapped text\n",
    "def draw_wrapped_text(draw, text, position, font, max_width, fill):\n",
    "    print(f\"Drawing wrapped text: {text}\")\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    while words:\n",
    "        line = ''\n",
    "        while words and font.getbbox(line + words[0])[2] <= max_width:\n",
    "            line += (words.pop(0) + ' ')\n",
    "        lines.append(line)\n",
    "    y_offset = position[1]\n",
    "    for line in lines:\n",
    "        draw.text((position[0], y_offset), line, font=font, fill=fill)\n",
    "        y_offset += font.getbbox(line)[3]  # Use getbbox for line height\n",
    "    print(f\"Wrapped text drawn at position {position}\")\n",
    "    return y_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Album Art Download!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch and download all popular album art for each artist\n",
    "def download_all_album_art(df, top_artists):\n",
    "    print(\"Downloading album art for top artists\")\n",
    "    album_art = {}\n",
    "    for artist in top_artists:\n",
    "        artist_data = df[df['artistName'] == artist]\n",
    "        if artist_data.empty:\n",
    "            continue\n",
    "        \n",
    "        art_urls = artist_data['album_artwork'].value_counts().index.tolist()\n",
    "        downloaded = False\n",
    "        for art_url in art_urls:\n",
    "            try:\n",
    "                response = requests.get(art_url)\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                \n",
    "                img_path = os.path.join(\"albums\", f'{artist}_album_art.jpg')\n",
    "                img.save(img_path)\n",
    "                \n",
    "                album_art[artist] = img_path\n",
    "                downloaded = True\n",
    "                print(f\"Downloaded album art for {artist}: {img_path}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {art_url} for {artist}: {e}\")\n",
    "                continue\n",
    "        if not downloaded:\n",
    "            print(f\"Could not download album art for {artist}\")\n",
    "    return album_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Function to create and save layout images\n",
    "def create_layout_image(title, top_artists, album_art, file_name, user_id, background):\n",
    "    print(f\"Creating layout image: {file_name}\")\n",
    "    width, height = background.size\n",
    "    image = background.copy()\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Define fonts\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "        title_font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        user_id_font = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "    except IOError:\n",
    "        # In case the fonts are not available on the system\n",
    "        font = ImageFont.load_default()\n",
    "        title_font = ImageFont.load_default()\n",
    "        user_id_font = ImageFont.load_default()\n",
    "    \n",
    "    # Draw title and user ID\n",
    "    draw.text((width / 2, 50), title, font=title_font, fill=\"white\", anchor=\"mm\")\n",
    "    draw.text((width / 2, 150), f\"User: {user_id}\", font=user_id_font, fill=\"white\", anchor=\"mm\")\n",
    "\n",
    "    y_offset = 250\n",
    "    x_offset = 50\n",
    "\n",
    "    for rank, (artist, value) in enumerate(top_artists.items(), start=1):\n",
    "        if artist not in album_art:\n",
    "            continue\n",
    "        \n",
    "        art = Image.open(album_art[artist]).resize((100, 100))\n",
    "        image.paste(art, (x_offset, y_offset))\n",
    "        \n",
    "        text = f\"{rank}. {artist}: {value}\"\n",
    "        draw.text((x_offset + 120, y_offset + 30), text, font=font, fill=\"white\")\n",
    "        y_offset += 120\n",
    "\n",
    "    image.save(file_name)\n",
    "    print(f\"Layout image saved as {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_filled_listening_data('ezra_listening_data_with_percentage.csv')\n",
    "\n",
    "# Calculate total listening time per user\n",
    "total_time = total_listening_time_per_user(df)\n",
    "print(\"Total listening time per user (in hours):\")\n",
    "print(total_time, \"\\n\")\n",
    "\n",
    "# Identify the biggest listening date\n",
    "biggest_date = biggest_listening_date(df)\n",
    "print(\"Biggest listening date:\")\n",
    "print(biggest_date, \"\\n\")\n",
    "\n",
    "# Analyze top 5 music tastes per month\n",
    "taste_per_month = music_taste_per_month(df)\n",
    "print(\"Top 5 artists per month:\")\n",
    "for month, artists in taste_per_month.items():\n",
    "    print(f\"Month {month}: {artists}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Determine the most common listening days and times\n",
    "common_days = common_listening_days_and_times(df)\n",
    "print(\"Most common listening days:\")\n",
    "print(common_days, \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Album Analysis Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Generate Instagram story-sized abstract background with Perlin noise and custom colormap\n",
    "    background = generate_abstract_background_with_noise(1080, 1920)\n",
    "\n",
    "    # Load unique songs data\n",
    "    unique_songs_file = 'unique_songs.csv'\n",
    "    unique_songs = pd.read_csv(unique_songs_file)\n",
    "\n",
    "    # Get user ID and construct the file path\n",
    "    user_name = get_user_id()\n",
    "    file_path = f'{user_name}_listening_data.csv'\n",
    "\n",
    "    try:\n",
    "        # Read the filled listening data\n",
    "        filled_listening_data = read_filled_listening_data(file_path)\n",
    "        \n",
    "        # Calculate percentage listened for each track\n",
    "        filled_listening_data = calculate_percentage_listened(filled_listening_data)\n",
    "        \n",
    "        # Calculate top listened-to artists\n",
    "        top_artists_count = top_artists_by_count(filled_listening_data).head(5)\n",
    "        top_artists_time = top_artists_by_time(filled_listening_data).head(5)\n",
    "        top_artists_weighted_time = top_artists_by_weighted_time(filled_listening_data).head(5)\n",
    "        \n",
    "        # Combine all top artists to ensure all album art is downloaded\n",
    "        all_top_artists = top_artists_count.index.union(top_artists_time.index).union(top_artists_weighted_time.index)\n",
    "        \n",
    "        # Download the most common album art for each artist\n",
    "        album_art = download_all_album_art(filled_listening_data, all_top_artists)\n",
    "        \n",
    "        # Create layout images with user ID in the file name and abstract background\n",
    "        create_layout_image(\"Top Artists by Count\", top_artists_count, album_art, f\"{user_name}_spotify_wrapped_top_artists_count.png\", user_name, background)\n",
    "        create_layout_image(\"Top Artists by Listening Time (minutes)\", {k: v / 60 for k, v in top_artists_time.items()}, album_art, f\"{user_name}_spotify_wrapped_top_artists_time.png\", user_name, background)\n",
    "        create_layout_image(\"Top Artists by Weighted Listening Time\", top_artists_weighted_time, album_art, f\"{user_name}_spotify_wrapped_top_artists_weighted_time.png\", user_name, background)\n",
    "        \n",
    "        print(\"Data processing and layout creation complete!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
